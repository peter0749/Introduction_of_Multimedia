[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:07.879010 20088 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fc66d5fc5cd  google::LogMessage::Fail()
    @     0x7fc66d5fe433  google::LogMessage::SendToLog()
    @     0x7fc66d5fc15b  google::LogMessage::Flush()
    @     0x7fc66d5fee1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fc66dd83fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fc66c56d830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.053818 20100 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f18d141a5cd  google::LogMessage::Fail()
    @     0x7f18d141c433  google::LogMessage::SendToLog()
    @     0x7f18d141a15b  google::LogMessage::Flush()
    @     0x7f18d141ce1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f18d1ba1fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f18d038b830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.205538 20112 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7ff167c325cd  google::LogMessage::Fail()
    @     0x7ff167c34433  google::LogMessage::SendToLog()
    @     0x7ff167c3215b  google::LogMessage::Flush()
    @     0x7ff167c34e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7ff1683b9fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7ff166ba3830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.358033 20124 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f98421da5cd  google::LogMessage::Fail()
    @     0x7f98421dc433  google::LogMessage::SendToLog()
    @     0x7f98421da15b  google::LogMessage::Flush()
    @     0x7f98421dce1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f9842961fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f984114b830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.512073 20136 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7ffacd67c5cd  google::LogMessage::Fail()
    @     0x7ffacd67e433  google::LogMessage::SendToLog()
    @     0x7ffacd67c15b  google::LogMessage::Flush()
    @     0x7ffacd67ee1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7ffacde03fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7ffacc5ed830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.666699 20148 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fab032b45cd  google::LogMessage::Fail()
    @     0x7fab032b6433  google::LogMessage::SendToLog()
    @     0x7fab032b415b  google::LogMessage::Flush()
    @     0x7fab032b6e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fab03a3bfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fab02225830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.820255 20160 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f2f81eeb5cd  google::LogMessage::Fail()
    @     0x7f2f81eed433  google::LogMessage::SendToLog()
    @     0x7f2f81eeb15b  google::LogMessage::Flush()
    @     0x7f2f81eede1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f2f82672fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f2f80e5c830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:08.971652 20172 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f76d3e735cd  google::LogMessage::Fail()
    @     0x7f76d3e75433  google::LogMessage::SendToLog()
    @     0x7f76d3e7315b  google::LogMessage::Flush()
    @     0x7f76d3e75e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f76d45fafb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f76d2de4830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:09.126180 20184 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fb4cdec25cd  google::LogMessage::Fail()
    @     0x7fb4cdec4433  google::LogMessage::SendToLog()
    @     0x7fb4cdec215b  google::LogMessage::Flush()
    @     0x7fb4cdec4e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fb4ce649fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fb4cce33830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:09.279342 20196 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f14f9fad5cd  google::LogMessage::Fail()
    @     0x7f14f9faf433  google::LogMessage::SendToLog()
    @     0x7f14f9fad15b  google::LogMessage::Flush()
    @     0x7f14f9fafe1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f14fa734fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f14f8f1e830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:09.431928 20208 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f5a4845f5cd  google::LogMessage::Fail()
    @     0x7f5a48461433  google::LogMessage::SendToLog()
    @     0x7f5a4845f15b  google::LogMessage::Flush()
    @     0x7f5a48461e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f5a48be6fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f5a473d0830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:09.582459 20220 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fbc9032c5cd  google::LogMessage::Fail()
    @     0x7fbc9032e433  google::LogMessage::SendToLog()
    @     0x7fbc9032c15b  google::LogMessage::Flush()
    @     0x7fbc9032ee1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fbc90ab3fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fbc8f29d830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:09.738656 20232 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f2d7f1885cd  google::LogMessage::Fail()
    @     0x7f2d7f18a433  google::LogMessage::SendToLog()
    @     0x7f2d7f18815b  google::LogMessage::Flush()
    @     0x7f2d7f18ae1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f2d7f90ffb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f2d7e0f9830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:09.891052 20244 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f8d9fe125cd  google::LogMessage::Fail()
    @     0x7f8d9fe14433  google::LogMessage::SendToLog()
    @     0x7f8d9fe1215b  google::LogMessage::Flush()
    @     0x7f8d9fe14e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f8da0599fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f8d9ed83830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.045501 20256 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fd3f045e5cd  google::LogMessage::Fail()
    @     0x7fd3f0460433  google::LogMessage::SendToLog()
    @     0x7fd3f045e15b  google::LogMessage::Flush()
    @     0x7fd3f0460e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fd3f0be5fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fd3ef3cf830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.198168 20268 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f1fca6c65cd  google::LogMessage::Fail()
    @     0x7f1fca6c8433  google::LogMessage::SendToLog()
    @     0x7f1fca6c615b  google::LogMessage::Flush()
    @     0x7f1fca6c8e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f1fcae4dfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f1fc9637830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.352998 20280 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fe0736df5cd  google::LogMessage::Fail()
    @     0x7fe0736e1433  google::LogMessage::SendToLog()
    @     0x7fe0736df15b  google::LogMessage::Flush()
    @     0x7fe0736e1e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fe073e66fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fe072650830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.505400 20292 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fcee3b825cd  google::LogMessage::Fail()
    @     0x7fcee3b84433  google::LogMessage::SendToLog()
    @     0x7fcee3b8215b  google::LogMessage::Flush()
    @     0x7fcee3b84e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fcee4309fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fcee2af3830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.660600 20304 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f26d79b45cd  google::LogMessage::Fail()
    @     0x7f26d79b6433  google::LogMessage::SendToLog()
    @     0x7f26d79b415b  google::LogMessage::Flush()
    @     0x7f26d79b6e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f26d813bfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f26d6925830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.815709 20316 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f62629315cd  google::LogMessage::Fail()
    @     0x7f6262933433  google::LogMessage::SendToLog()
    @     0x7f626293115b  google::LogMessage::Flush()
    @     0x7f6262933e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f62630b8fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f62618a2830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:10.968410 20328 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f603f14b5cd  google::LogMessage::Fail()
    @     0x7f603f14d433  google::LogMessage::SendToLog()
    @     0x7f603f14b15b  google::LogMessage::Flush()
    @     0x7f603f14de1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f603f8d2fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f603e0bc830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:11.120741 20340 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fbada0985cd  google::LogMessage::Fail()
    @     0x7fbada09a433  google::LogMessage::SendToLog()
    @     0x7fbada09815b  google::LogMessage::Flush()
    @     0x7fbada09ae1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fbada81ffb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fbad9009830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:11.272387 20352 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fb9aba875cd  google::LogMessage::Fail()
    @     0x7fb9aba89433  google::LogMessage::SendToLog()
    @     0x7fb9aba8715b  google::LogMessage::Flush()
    @     0x7fb9aba89e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fb9ac20efb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fb9aa9f8830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:11.425511 20364 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f800d1165cd  google::LogMessage::Fail()
    @     0x7f800d118433  google::LogMessage::SendToLog()
    @     0x7f800d11615b  google::LogMessage::Flush()
    @     0x7f800d118e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f800d89dfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f800c087830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:11.577472 20376 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f95a0e595cd  google::LogMessage::Fail()
    @     0x7f95a0e5b433  google::LogMessage::SendToLog()
    @     0x7f95a0e5915b  google::LogMessage::Flush()
    @     0x7f95a0e5be1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f95a15e0fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f959fdca830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:11.732411 20388 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f232f2cf5cd  google::LogMessage::Fail()
    @     0x7f232f2d1433  google::LogMessage::SendToLog()
    @     0x7f232f2cf15b  google::LogMessage::Flush()
    @     0x7f232f2d1e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f232fa56fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f232e240830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:11.885676 20400 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f2807a145cd  google::LogMessage::Fail()
    @     0x7f2807a16433  google::LogMessage::SendToLog()
    @     0x7f2807a1415b  google::LogMessage::Flush()
    @     0x7f2807a16e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f280819bfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f2806985830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:51:12.040521 20412 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fcb71c665cd  google::LogMessage::Fail()
    @     0x7fcb71c68433  google::LogMessage::SendToLog()
    @     0x7fcb71c6615b  google::LogMessage::Flush()
    @     0x7fcb71c68e1e  google::LogMessageFatal::~LogMessageFatal()
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:11.701988 20457 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fdf03bc75cd  google::LogMessage::Fail()
    @     0x7fdf03bc9433  google::LogMessage::SendToLog()
    @     0x7fdf03bc715b  google::LogMessage::Flush()
    @     0x7fdf03bc9e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fdf0434efb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fdf02b38830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:11.857537 20469 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f83a09af5cd  google::LogMessage::Fail()
    @     0x7f83a09b1433  google::LogMessage::SendToLog()
    @     0x7f83a09af15b  google::LogMessage::Flush()
    @     0x7f83a09b1e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f83a1136fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f839f920830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:12.013387 20481 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7feb8fe005cd  google::LogMessage::Fail()
    @     0x7feb8fe02433  google::LogMessage::SendToLog()
    @     0x7feb8fe0015b  google::LogMessage::Flush()
    @     0x7feb8fe02e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7feb90587fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7feb8ed71830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:12.164932 20493 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fd29d11c5cd  google::LogMessage::Fail()
    @     0x7fd29d11e433  google::LogMessage::SendToLog()
    @     0x7fd29d11c15b  google::LogMessage::Flush()
    @     0x7fd29d11ee1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fd29d8a3fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fd29c08d830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:12.317178 20505 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f64718cf5cd  google::LogMessage::Fail()
    @     0x7f64718d1433  google::LogMessage::SendToLog()
    @     0x7f64718cf15b  google::LogMessage::Flush()
    @     0x7f64718d1e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f6472056fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f6470840830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:12.471889 20517 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fe7c36085cd  google::LogMessage::Fail()
    @     0x7fe7c360a433  google::LogMessage::SendToLog()
    @     0x7fe7c360815b  google::LogMessage::Flush()
    @     0x7fe7c360ae1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fe7c3d8ffb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fe7c2579830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:12.628981 20529 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f80cccb35cd  google::LogMessage::Fail()
    @     0x7f80cccb5433  google::LogMessage::SendToLog()
    @     0x7f80cccb315b  google::LogMessage::Flush()
    @     0x7f80cccb5e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f80cd43afb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f80cbc24830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:12.784006 20541 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fce418085cd  google::LogMessage::Fail()
    @     0x7fce4180a433  google::LogMessage::SendToLog()
    @     0x7fce4180815b  google::LogMessage::Flush()
    @     0x7fce4180ae1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fce41f8ffb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fce40779830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:13.077827 20553 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f029afcb5cd  google::LogMessage::Fail()
    @     0x7f029afcd433  google::LogMessage::SendToLog()
    @     0x7f029afcb15b  google::LogMessage::Flush()
    @     0x7f029afcde1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f029b752fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f0299f3c830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:13.232043 20565 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f97955d05cd  google::LogMessage::Fail()
    @     0x7f97955d2433  google::LogMessage::SendToLog()
    @     0x7f97955d015b  google::LogMessage::Flush()
    @     0x7f97955d2e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f9795d57fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f9794541830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:13.389202 20577 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fd5c2f3e5cd  google::LogMessage::Fail()
    @     0x7fd5c2f40433  google::LogMessage::SendToLog()
    @     0x7fd5c2f3e15b  google::LogMessage::Flush()
    @     0x7fd5c2f40e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fd5c36c5fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fd5c1eaf830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:13.543117 20589 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fd5d47da5cd  google::LogMessage::Fail()
    @     0x7fd5d47dc433  google::LogMessage::SendToLog()
    @     0x7fd5d47da15b  google::LogMessage::Flush()
    @     0x7fd5d47dce1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fd5d4f61fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fd5d374b830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:13.698282 20601 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fc7f54cb5cd  google::LogMessage::Fail()
    @     0x7fc7f54cd433  google::LogMessage::SendToLog()
    @     0x7fc7f54cb15b  google::LogMessage::Flush()
    @     0x7fc7f54cde1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fc7f5c52fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fc7f443c830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:13.848713 20613 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fc44cd155cd  google::LogMessage::Fail()
    @     0x7fc44cd17433  google::LogMessage::SendToLog()
    @     0x7fc44cd1515b  google::LogMessage::Flush()
    @     0x7fc44cd17e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fc44d49cfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7fc44bc86830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:14.001719 20625 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f6023b225cd  google::LogMessage::Fail()
    @     0x7f6023b24433  google::LogMessage::SendToLog()
    @     0x7f6023b2215b  google::LogMessage::Flush()
    @     0x7f6023b24e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f60242a9fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f6022a93830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:14.155774 20637 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f9139cc35cd  google::LogMessage::Fail()
    @     0x7f9139cc5433  google::LogMessage::SendToLog()
    @     0x7f9139cc315b  google::LogMessage::Flush()
    @     0x7f9139cc5e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f913a44afb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f9138c34830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:14.311269 20649 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f9ce70495cd  google::LogMessage::Fail()
    @     0x7f9ce704b433  google::LogMessage::SendToLog()
    @     0x7f9ce704915b  google::LogMessage::Flush()
    @     0x7f9ce704be1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f9ce77d0fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f9ce5fba830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:14.463140 20661 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f799fe755cd  google::LogMessage::Fail()
    @     0x7f799fe77433  google::LogMessage::SendToLog()
    @     0x7f799fe7515b  google::LogMessage::Flush()
    @     0x7f799fe77e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f79a05fcfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f799ede6830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:14.619329 20673 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7f888013c5cd  google::LogMessage::Fail()
    @     0x7f888013e433  google::LogMessage::SendToLog()
    @     0x7f888013c15b  google::LogMessage::Flush()
    @     0x7f888013ee1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f88808c3fb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
    @     0x7f887f0ad830  __libc_start_main
    @           0x407db9  _start
    @              (nil)  (unknown)
[libprotobuf ERROR google/protobuf/text_format.cc:274] Error parsing text-format caffe.SolverParameter: 1:5: Message type "caffe.SolverParameter" has no field named "name".
F0110 18:52:14.772964 20685 upgrade_proto.cpp:1095] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse SolverParameter file: ./temp_net.prototxt
*** Check failure stack trace: ***
    @     0x7fb7b8a245cd  google::LogMessage::Fail()
    @     0x7fb7b8a26433  google::LogMessage::SendToLog()
    @     0x7fb7b8a2415b  google::LogMessage::Flush()
    @     0x7fb7b8a26e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fb7b91abfb1  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x40a8ba  train()
    @           0x407590  main
I0110 18:55:10.464963 20857 caffe.cpp:217] Using GPUs 0
I0110 18:55:10.465535 20857 caffe.cpp:222] GPU 0: GeForce 840M
I0110 18:55:10.680001 20857 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2383
test_interval: 4000
base_lr: 0.01
display: 200
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 12000
snapshot: 4000
snapshot_prefix: "models/1/caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "temp_net.prototxt"
train_state {
  level: 0
  stage: ""
}
I0110 18:55:10.680138 20857 solver.cpp:91] Creating training net from net file: temp_net.prototxt
I0110 18:55:10.680414 20857 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:55:10.680423 20857 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:55:10.680438 20857 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0110 18:55:10.680573 20857 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "train_loc.txt"
    batch_size: 16
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "label_list/train_label-1.txt"
    batch_size: 16
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:55:10.680652 20857 layer_factory.hpp:77] Creating layer data
I0110 18:55:10.680665 20857 net.cpp:100] Creating Layer data
I0110 18:55:10.680670 20857 net.cpp:408] data -> data
I0110 18:55:10.680691 20857 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: train_loc.txt
I0110 18:55:10.680732 20857 hdf5_data_layer.cpp:93] Number of HDF5 files: 38
I0110 18:55:10.885210 20857 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0110 18:55:18.030613 20857 net.cpp:150] Setting up data
I0110 18:55:18.030702 20857 net.cpp:157] Top shape: 16 3 256 256 (3145728)
I0110 18:55:18.030719 20857 net.cpp:165] Memory required for data: 12582912
I0110 18:55:18.030740 20857 layer_factory.hpp:77] Creating layer data
I0110 18:55:18.030771 20857 net.cpp:100] Creating Layer data
I0110 18:55:18.030788 20857 net.cpp:408] data -> label
I0110 18:55:18.030817 20857 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/train_label-1.txt
I0110 18:55:18.030994 20857 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:55:18.031988 20857 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0110 18:55:18.034332 20857 net.cpp:150] Setting up data
I0110 18:55:18.034392 20857 net.cpp:157] Top shape: 16 1 1 1 (16)
I0110 18:55:18.034405 20857 net.cpp:165] Memory required for data: 12582976
I0110 18:55:18.034420 20857 layer_factory.hpp:77] Creating layer conv1
I0110 18:55:18.034466 20857 net.cpp:100] Creating Layer conv1
I0110 18:55:18.034484 20857 net.cpp:434] conv1 <- data
I0110 18:55:18.034515 20857 net.cpp:408] conv1 -> conv1
I0110 18:55:18.688172 20857 net.cpp:150] Setting up conv1
I0110 18:55:18.688212 20857 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:55:18.688217 20857 net.cpp:165] Memory required for data: 36200512
I0110 18:55:18.688240 20857 layer_factory.hpp:77] Creating layer relu1
I0110 18:55:18.688251 20857 net.cpp:100] Creating Layer relu1
I0110 18:55:18.688256 20857 net.cpp:434] relu1 <- conv1
I0110 18:55:18.688262 20857 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:55:18.688443 20857 net.cpp:150] Setting up relu1
I0110 18:55:18.688453 20857 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:55:18.688457 20857 net.cpp:165] Memory required for data: 59818048
I0110 18:55:18.688462 20857 layer_factory.hpp:77] Creating layer norm1
I0110 18:55:18.688488 20857 net.cpp:100] Creating Layer norm1
I0110 18:55:18.688493 20857 net.cpp:434] norm1 <- conv1
I0110 18:55:18.688510 20857 net.cpp:408] norm1 -> norm1
I0110 18:55:18.688926 20857 net.cpp:150] Setting up norm1
I0110 18:55:18.688946 20857 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:55:18.688951 20857 net.cpp:165] Memory required for data: 83435584
I0110 18:55:18.688956 20857 layer_factory.hpp:77] Creating layer pool1
I0110 18:55:18.688964 20857 net.cpp:100] Creating Layer pool1
I0110 18:55:18.688968 20857 net.cpp:434] pool1 <- norm1
I0110 18:55:18.688977 20857 net.cpp:408] pool1 -> pool1
I0110 18:55:18.689025 20857 net.cpp:150] Setting up pool1
I0110 18:55:18.689035 20857 net.cpp:157] Top shape: 16 96 31 31 (1476096)
I0110 18:55:18.689039 20857 net.cpp:165] Memory required for data: 89339968
I0110 18:55:18.689043 20857 layer_factory.hpp:77] Creating layer conv2
I0110 18:55:18.689055 20857 net.cpp:100] Creating Layer conv2
I0110 18:55:18.689060 20857 net.cpp:434] conv2 <- pool1
I0110 18:55:18.689067 20857 net.cpp:408] conv2 -> conv2
I0110 18:55:18.695426 20857 net.cpp:150] Setting up conv2
I0110 18:55:18.695463 20857 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:55:18.695468 20857 net.cpp:165] Memory required for data: 105084992
I0110 18:55:18.695483 20857 layer_factory.hpp:77] Creating layer relu2
I0110 18:55:18.695493 20857 net.cpp:100] Creating Layer relu2
I0110 18:55:18.695498 20857 net.cpp:434] relu2 <- conv2
I0110 18:55:18.695508 20857 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:55:18.696025 20857 net.cpp:150] Setting up relu2
I0110 18:55:18.696039 20857 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:55:18.696044 20857 net.cpp:165] Memory required for data: 120830016
I0110 18:55:18.696048 20857 layer_factory.hpp:77] Creating layer norm2
I0110 18:55:18.696060 20857 net.cpp:100] Creating Layer norm2
I0110 18:55:18.696065 20857 net.cpp:434] norm2 <- conv2
I0110 18:55:18.696072 20857 net.cpp:408] norm2 -> norm2
I0110 18:55:18.696285 20857 net.cpp:150] Setting up norm2
I0110 18:55:18.696296 20857 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:55:18.696300 20857 net.cpp:165] Memory required for data: 136575040
I0110 18:55:18.696305 20857 layer_factory.hpp:77] Creating layer pool2
I0110 18:55:18.696312 20857 net.cpp:100] Creating Layer pool2
I0110 18:55:18.696316 20857 net.cpp:434] pool2 <- norm2
I0110 18:55:18.696323 20857 net.cpp:408] pool2 -> pool2
I0110 18:55:18.696719 20857 net.cpp:150] Setting up pool2
I0110 18:55:18.696732 20857 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:55:18.696734 20857 net.cpp:165] Memory required for data: 140261440
I0110 18:55:18.696738 20857 layer_factory.hpp:77] Creating layer conv3
I0110 18:55:18.696751 20857 net.cpp:100] Creating Layer conv3
I0110 18:55:18.696755 20857 net.cpp:434] conv3 <- pool2
I0110 18:55:18.696763 20857 net.cpp:408] conv3 -> conv3
I0110 18:55:18.707967 20857 net.cpp:150] Setting up conv3
I0110 18:55:18.707998 20857 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:18.708003 20857 net.cpp:165] Memory required for data: 145791040
I0110 18:55:18.708019 20857 layer_factory.hpp:77] Creating layer relu3
I0110 18:55:18.708030 20857 net.cpp:100] Creating Layer relu3
I0110 18:55:18.708036 20857 net.cpp:434] relu3 <- conv3
I0110 18:55:18.708045 20857 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:55:18.708222 20857 net.cpp:150] Setting up relu3
I0110 18:55:18.708235 20857 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:18.708238 20857 net.cpp:165] Memory required for data: 151320640
I0110 18:55:18.708242 20857 layer_factory.hpp:77] Creating layer conv4
I0110 18:55:18.708256 20857 net.cpp:100] Creating Layer conv4
I0110 18:55:18.708261 20857 net.cpp:434] conv4 <- conv3
I0110 18:55:18.708269 20857 net.cpp:408] conv4 -> conv4
I0110 18:55:18.717576 20857 net.cpp:150] Setting up conv4
I0110 18:55:18.717612 20857 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:18.717617 20857 net.cpp:165] Memory required for data: 156850240
I0110 18:55:18.717627 20857 layer_factory.hpp:77] Creating layer relu4
I0110 18:55:18.717646 20857 net.cpp:100] Creating Layer relu4
I0110 18:55:18.717653 20857 net.cpp:434] relu4 <- conv4
I0110 18:55:18.717660 20857 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:55:18.717820 20857 net.cpp:150] Setting up relu4
I0110 18:55:18.717833 20857 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:18.717838 20857 net.cpp:165] Memory required for data: 162379840
I0110 18:55:18.717841 20857 layer_factory.hpp:77] Creating layer conv5
I0110 18:55:18.717852 20857 net.cpp:100] Creating Layer conv5
I0110 18:55:18.717856 20857 net.cpp:434] conv5 <- conv4
I0110 18:55:18.717864 20857 net.cpp:408] conv5 -> conv5
I0110 18:55:18.724644 20857 net.cpp:150] Setting up conv5
I0110 18:55:18.724683 20857 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:55:18.724687 20857 net.cpp:165] Memory required for data: 166066240
I0110 18:55:18.724699 20857 layer_factory.hpp:77] Creating layer relu5
I0110 18:55:18.724709 20857 net.cpp:100] Creating Layer relu5
I0110 18:55:18.724712 20857 net.cpp:434] relu5 <- conv5
I0110 18:55:18.724720 20857 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:55:18.724876 20857 net.cpp:150] Setting up relu5
I0110 18:55:18.724885 20857 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:55:18.724889 20857 net.cpp:165] Memory required for data: 169752640
I0110 18:55:18.724892 20857 layer_factory.hpp:77] Creating layer pool5
I0110 18:55:18.724902 20857 net.cpp:100] Creating Layer pool5
I0110 18:55:18.724906 20857 net.cpp:434] pool5 <- conv5
I0110 18:55:18.724912 20857 net.cpp:408] pool5 -> pool5
I0110 18:55:18.725251 20857 net.cpp:150] Setting up pool5
I0110 18:55:18.725265 20857 net.cpp:157] Top shape: 16 256 7 7 (200704)
I0110 18:55:18.725267 20857 net.cpp:165] Memory required for data: 170555456
I0110 18:55:18.725271 20857 layer_factory.hpp:77] Creating layer fc6
I0110 18:55:18.725278 20857 net.cpp:100] Creating Layer fc6
I0110 18:55:18.725282 20857 net.cpp:434] fc6 <- pool5
I0110 18:55:18.725288 20857 net.cpp:408] fc6 -> fc6
I0110 18:55:19.226795 20857 net.cpp:150] Setting up fc6
I0110 18:55:19.226847 20857 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:19.226852 20857 net.cpp:165] Memory required for data: 170817600
I0110 18:55:19.226863 20857 layer_factory.hpp:77] Creating layer relu6
I0110 18:55:19.226876 20857 net.cpp:100] Creating Layer relu6
I0110 18:55:19.226881 20857 net.cpp:434] relu6 <- fc6
I0110 18:55:19.226887 20857 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:55:19.227355 20857 net.cpp:150] Setting up relu6
I0110 18:55:19.227367 20857 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:19.227371 20857 net.cpp:165] Memory required for data: 171079744
I0110 18:55:19.227375 20857 layer_factory.hpp:77] Creating layer drop6
I0110 18:55:19.227381 20857 net.cpp:100] Creating Layer drop6
I0110 18:55:19.227385 20857 net.cpp:434] drop6 <- fc6
I0110 18:55:19.227390 20857 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:55:19.227418 20857 net.cpp:150] Setting up drop6
I0110 18:55:19.227424 20857 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:19.227427 20857 net.cpp:165] Memory required for data: 171341888
I0110 18:55:19.227430 20857 layer_factory.hpp:77] Creating layer fc7
I0110 18:55:19.227438 20857 net.cpp:100] Creating Layer fc7
I0110 18:55:19.227442 20857 net.cpp:434] fc7 <- fc6
I0110 18:55:19.227447 20857 net.cpp:408] fc7 -> fc7
I0110 18:55:19.393605 20857 net.cpp:150] Setting up fc7
I0110 18:55:19.393654 20857 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:19.393661 20857 net.cpp:165] Memory required for data: 171604032
I0110 18:55:19.393672 20857 layer_factory.hpp:77] Creating layer relu7
I0110 18:55:19.393693 20857 net.cpp:100] Creating Layer relu7
I0110 18:55:19.393698 20857 net.cpp:434] relu7 <- fc7
I0110 18:55:19.393705 20857 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:55:19.393934 20857 net.cpp:150] Setting up relu7
I0110 18:55:19.393945 20857 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:19.393949 20857 net.cpp:165] Memory required for data: 171866176
I0110 18:55:19.393954 20857 layer_factory.hpp:77] Creating layer drop7
I0110 18:55:19.393975 20857 net.cpp:100] Creating Layer drop7
I0110 18:55:19.393980 20857 net.cpp:434] drop7 <- fc7
I0110 18:55:19.393985 20857 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:55:19.394016 20857 net.cpp:150] Setting up drop7
I0110 18:55:19.394023 20857 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:19.394029 20857 net.cpp:165] Memory required for data: 172128320
I0110 18:55:19.394032 20857 layer_factory.hpp:77] Creating layer fc8
I0110 18:55:19.394042 20857 net.cpp:100] Creating Layer fc8
I0110 18:55:19.394044 20857 net.cpp:434] fc8 <- fc7
I0110 18:55:19.394050 20857 net.cpp:408] fc8 -> fc8
I0110 18:55:19.394184 20857 net.cpp:150] Setting up fc8
I0110 18:55:19.394191 20857 net.cpp:157] Top shape: 16 1 (16)
I0110 18:55:19.394193 20857 net.cpp:165] Memory required for data: 172128384
I0110 18:55:19.394199 20857 layer_factory.hpp:77] Creating layer loss
I0110 18:55:19.394206 20857 net.cpp:100] Creating Layer loss
I0110 18:55:19.394212 20857 net.cpp:434] loss <- fc8
I0110 18:55:19.394215 20857 net.cpp:434] loss <- label
I0110 18:55:19.394222 20857 net.cpp:408] loss -> loss
I0110 18:55:19.394233 20857 layer_factory.hpp:77] Creating layer loss
I0110 18:55:19.394732 20857 net.cpp:150] Setting up loss
I0110 18:55:19.394744 20857 net.cpp:157] Top shape: (1)
I0110 18:55:19.394747 20857 net.cpp:160]     with loss weight 1
I0110 18:55:19.394770 20857 net.cpp:165] Memory required for data: 172128388
I0110 18:55:19.394774 20857 net.cpp:226] loss needs backward computation.
I0110 18:55:19.394781 20857 net.cpp:226] fc8 needs backward computation.
I0110 18:55:19.394784 20857 net.cpp:226] drop7 needs backward computation.
I0110 18:55:19.394788 20857 net.cpp:226] relu7 needs backward computation.
I0110 18:55:19.394790 20857 net.cpp:226] fc7 needs backward computation.
I0110 18:55:19.394794 20857 net.cpp:226] drop6 needs backward computation.
I0110 18:55:19.394798 20857 net.cpp:226] relu6 needs backward computation.
I0110 18:55:19.394800 20857 net.cpp:226] fc6 needs backward computation.
I0110 18:55:19.394804 20857 net.cpp:226] pool5 needs backward computation.
I0110 18:55:19.394807 20857 net.cpp:226] relu5 needs backward computation.
I0110 18:55:19.394810 20857 net.cpp:226] conv5 needs backward computation.
I0110 18:55:19.394814 20857 net.cpp:226] relu4 needs backward computation.
I0110 18:55:19.394817 20857 net.cpp:226] conv4 needs backward computation.
I0110 18:55:19.394821 20857 net.cpp:226] relu3 needs backward computation.
I0110 18:55:19.394824 20857 net.cpp:226] conv3 needs backward computation.
I0110 18:55:19.394827 20857 net.cpp:226] pool2 needs backward computation.
I0110 18:55:19.394831 20857 net.cpp:226] norm2 needs backward computation.
I0110 18:55:19.394834 20857 net.cpp:226] relu2 needs backward computation.
I0110 18:55:19.394839 20857 net.cpp:226] conv2 needs backward computation.
I0110 18:55:19.394841 20857 net.cpp:226] pool1 needs backward computation.
I0110 18:55:19.394845 20857 net.cpp:226] norm1 needs backward computation.
I0110 18:55:19.394848 20857 net.cpp:226] relu1 needs backward computation.
I0110 18:55:19.394851 20857 net.cpp:226] conv1 needs backward computation.
I0110 18:55:19.394855 20857 net.cpp:228] data does not need backward computation.
I0110 18:55:19.394858 20857 net.cpp:228] data does not need backward computation.
I0110 18:55:19.394861 20857 net.cpp:270] This network produces output loss
I0110 18:55:19.394876 20857 net.cpp:283] Network initialization done.
I0110 18:55:19.395133 20857 solver.cpp:181] Creating test net (#0) specified by net file: temp_net.prototxt
I0110 18:55:19.395161 20857 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:55:19.395166 20857 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:55:19.395309 20857 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "test_loc.txt"
    batch_size: 8
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "label_list/test_label-1.txt"
    batch_size: 8
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:55:19.395406 20857 layer_factory.hpp:77] Creating layer data
I0110 18:55:19.395416 20857 net.cpp:100] Creating Layer data
I0110 18:55:19.395419 20857 net.cpp:408] data -> data
I0110 18:55:19.395426 20857 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: test_loc.txt
I0110 18:55:19.395447 20857 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0110 18:55:19.732077 20857 net.cpp:150] Setting up data
I0110 18:55:19.732118 20857 net.cpp:157] Top shape: 8 3 256 256 (1572864)
I0110 18:55:19.732123 20857 net.cpp:165] Memory required for data: 6291456
I0110 18:55:19.732130 20857 layer_factory.hpp:77] Creating layer data
I0110 18:55:19.732143 20857 net.cpp:100] Creating Layer data
I0110 18:55:19.732149 20857 net.cpp:408] data -> label
I0110 18:55:19.732161 20857 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/test_label-1.txt
I0110 18:55:19.732185 20857 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:55:19.733182 20857 net.cpp:150] Setting up data
I0110 18:55:19.733206 20857 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:55:19.733209 20857 net.cpp:165] Memory required for data: 6291488
I0110 18:55:19.733213 20857 layer_factory.hpp:77] Creating layer label_data_0_split
I0110 18:55:19.733230 20857 net.cpp:100] Creating Layer label_data_0_split
I0110 18:55:19.733235 20857 net.cpp:434] label_data_0_split <- label
I0110 18:55:19.733242 20857 net.cpp:408] label_data_0_split -> label_data_0_split_0
I0110 18:55:19.733250 20857 net.cpp:408] label_data_0_split -> label_data_0_split_1
I0110 18:55:19.733285 20857 net.cpp:150] Setting up label_data_0_split
I0110 18:55:19.733291 20857 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:55:19.733295 20857 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:55:19.733299 20857 net.cpp:165] Memory required for data: 6291552
I0110 18:55:19.733301 20857 layer_factory.hpp:77] Creating layer conv1
I0110 18:55:19.733312 20857 net.cpp:100] Creating Layer conv1
I0110 18:55:19.733316 20857 net.cpp:434] conv1 <- data
I0110 18:55:19.733321 20857 net.cpp:408] conv1 -> conv1
I0110 18:55:19.734560 20857 net.cpp:150] Setting up conv1
I0110 18:55:19.734573 20857 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:55:19.734576 20857 net.cpp:165] Memory required for data: 18100320
I0110 18:55:19.734586 20857 layer_factory.hpp:77] Creating layer relu1
I0110 18:55:19.734593 20857 net.cpp:100] Creating Layer relu1
I0110 18:55:19.734597 20857 net.cpp:434] relu1 <- conv1
I0110 18:55:19.734602 20857 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:55:19.734917 20857 net.cpp:150] Setting up relu1
I0110 18:55:19.734928 20857 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:55:19.734932 20857 net.cpp:165] Memory required for data: 29909088
I0110 18:55:19.734935 20857 layer_factory.hpp:77] Creating layer norm1
I0110 18:55:19.734943 20857 net.cpp:100] Creating Layer norm1
I0110 18:55:19.734947 20857 net.cpp:434] norm1 <- conv1
I0110 18:55:19.734952 20857 net.cpp:408] norm1 -> norm1
I0110 18:55:19.735108 20857 net.cpp:150] Setting up norm1
I0110 18:55:19.735117 20857 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:55:19.735121 20857 net.cpp:165] Memory required for data: 41717856
I0110 18:55:19.735124 20857 layer_factory.hpp:77] Creating layer pool1
I0110 18:55:19.735131 20857 net.cpp:100] Creating Layer pool1
I0110 18:55:19.735146 20857 net.cpp:434] pool1 <- norm1
I0110 18:55:19.735152 20857 net.cpp:408] pool1 -> pool1
I0110 18:55:19.735183 20857 net.cpp:150] Setting up pool1
I0110 18:55:19.735189 20857 net.cpp:157] Top shape: 8 96 31 31 (738048)
I0110 18:55:19.735193 20857 net.cpp:165] Memory required for data: 44670048
I0110 18:55:19.735199 20857 layer_factory.hpp:77] Creating layer conv2
I0110 18:55:19.735208 20857 net.cpp:100] Creating Layer conv2
I0110 18:55:19.735211 20857 net.cpp:434] conv2 <- pool1
I0110 18:55:19.735216 20857 net.cpp:408] conv2 -> conv2
I0110 18:55:19.740053 20857 net.cpp:150] Setting up conv2
I0110 18:55:19.740078 20857 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:55:19.740082 20857 net.cpp:165] Memory required for data: 52542560
I0110 18:55:19.740092 20857 layer_factory.hpp:77] Creating layer relu2
I0110 18:55:19.740101 20857 net.cpp:100] Creating Layer relu2
I0110 18:55:19.740105 20857 net.cpp:434] relu2 <- conv2
I0110 18:55:19.740111 20857 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:55:19.740430 20857 net.cpp:150] Setting up relu2
I0110 18:55:19.740442 20857 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:55:19.740444 20857 net.cpp:165] Memory required for data: 60415072
I0110 18:55:19.740448 20857 layer_factory.hpp:77] Creating layer norm2
I0110 18:55:19.740455 20857 net.cpp:100] Creating Layer norm2
I0110 18:55:19.740459 20857 net.cpp:434] norm2 <- conv2
I0110 18:55:19.740464 20857 net.cpp:408] norm2 -> norm2
I0110 18:55:19.740624 20857 net.cpp:150] Setting up norm2
I0110 18:55:19.740633 20857 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:55:19.740636 20857 net.cpp:165] Memory required for data: 68287584
I0110 18:55:19.740640 20857 layer_factory.hpp:77] Creating layer pool2
I0110 18:55:19.740645 20857 net.cpp:100] Creating Layer pool2
I0110 18:55:19.740649 20857 net.cpp:434] pool2 <- norm2
I0110 18:55:19.740654 20857 net.cpp:408] pool2 -> pool2
I0110 18:55:19.740983 20857 net.cpp:150] Setting up pool2
I0110 18:55:19.740993 20857 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:55:19.740998 20857 net.cpp:165] Memory required for data: 70130784
I0110 18:55:19.741000 20857 layer_factory.hpp:77] Creating layer conv3
I0110 18:55:19.741008 20857 net.cpp:100] Creating Layer conv3
I0110 18:55:19.741013 20857 net.cpp:434] conv3 <- pool2
I0110 18:55:19.741019 20857 net.cpp:408] conv3 -> conv3
I0110 18:55:19.750859 20857 net.cpp:150] Setting up conv3
I0110 18:55:19.750892 20857 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:19.750896 20857 net.cpp:165] Memory required for data: 72895584
I0110 18:55:19.750907 20857 layer_factory.hpp:77] Creating layer relu3
I0110 18:55:19.750916 20857 net.cpp:100] Creating Layer relu3
I0110 18:55:19.750921 20857 net.cpp:434] relu3 <- conv3
I0110 18:55:19.750927 20857 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:55:19.751252 20857 net.cpp:150] Setting up relu3
I0110 18:55:19.751265 20857 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:19.751267 20857 net.cpp:165] Memory required for data: 75660384
I0110 18:55:19.751271 20857 layer_factory.hpp:77] Creating layer conv4
I0110 18:55:19.751281 20857 net.cpp:100] Creating Layer conv4
I0110 18:55:19.751284 20857 net.cpp:434] conv4 <- conv3
I0110 18:55:19.751291 20857 net.cpp:408] conv4 -> conv4
I0110 18:55:19.760315 20857 net.cpp:150] Setting up conv4
I0110 18:55:19.760351 20857 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:19.760356 20857 net.cpp:165] Memory required for data: 78425184
I0110 18:55:19.760367 20857 layer_factory.hpp:77] Creating layer relu4
I0110 18:55:19.760376 20857 net.cpp:100] Creating Layer relu4
I0110 18:55:19.760381 20857 net.cpp:434] relu4 <- conv4
I0110 18:55:19.760390 20857 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:55:19.760557 20857 net.cpp:150] Setting up relu4
I0110 18:55:19.760567 20857 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:19.760571 20857 net.cpp:165] Memory required for data: 81189984
I0110 18:55:19.760576 20857 layer_factory.hpp:77] Creating layer conv5
I0110 18:55:19.760586 20857 net.cpp:100] Creating Layer conv5
I0110 18:55:19.760601 20857 net.cpp:434] conv5 <- conv4
I0110 18:55:19.760608 20857 net.cpp:408] conv5 -> conv5
I0110 18:55:19.767076 20857 net.cpp:150] Setting up conv5
I0110 18:55:19.767105 20857 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:55:19.767109 20857 net.cpp:165] Memory required for data: 83033184
I0110 18:55:19.767127 20857 layer_factory.hpp:77] Creating layer relu5
I0110 18:55:19.767138 20857 net.cpp:100] Creating Layer relu5
I0110 18:55:19.767143 20857 net.cpp:434] relu5 <- conv5
I0110 18:55:19.767148 20857 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:55:19.767302 20857 net.cpp:150] Setting up relu5
I0110 18:55:19.767310 20857 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:55:19.767313 20857 net.cpp:165] Memory required for data: 84876384
I0110 18:55:19.767318 20857 layer_factory.hpp:77] Creating layer pool5
I0110 18:55:19.767324 20857 net.cpp:100] Creating Layer pool5
I0110 18:55:19.767328 20857 net.cpp:434] pool5 <- conv5
I0110 18:55:19.767333 20857 net.cpp:408] pool5 -> pool5
I0110 18:55:19.767688 20857 net.cpp:150] Setting up pool5
I0110 18:55:19.767699 20857 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0110 18:55:19.767702 20857 net.cpp:165] Memory required for data: 85277792
I0110 18:55:19.767706 20857 layer_factory.hpp:77] Creating layer fc6
I0110 18:55:19.767714 20857 net.cpp:100] Creating Layer fc6
I0110 18:55:19.767719 20857 net.cpp:434] fc6 <- pool5
I0110 18:55:19.767724 20857 net.cpp:408] fc6 -> fc6
I0110 18:55:20.258385 20857 net.cpp:150] Setting up fc6
I0110 18:55:20.258437 20857 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:20.258442 20857 net.cpp:165] Memory required for data: 85408864
I0110 18:55:20.258452 20857 layer_factory.hpp:77] Creating layer relu6
I0110 18:55:20.258462 20857 net.cpp:100] Creating Layer relu6
I0110 18:55:20.258467 20857 net.cpp:434] relu6 <- fc6
I0110 18:55:20.258476 20857 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:55:20.258690 20857 net.cpp:150] Setting up relu6
I0110 18:55:20.258699 20857 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:20.258702 20857 net.cpp:165] Memory required for data: 85539936
I0110 18:55:20.258707 20857 layer_factory.hpp:77] Creating layer drop6
I0110 18:55:20.258713 20857 net.cpp:100] Creating Layer drop6
I0110 18:55:20.258718 20857 net.cpp:434] drop6 <- fc6
I0110 18:55:20.258721 20857 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:55:20.258749 20857 net.cpp:150] Setting up drop6
I0110 18:55:20.258754 20857 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:20.258756 20857 net.cpp:165] Memory required for data: 85671008
I0110 18:55:20.258759 20857 layer_factory.hpp:77] Creating layer fc7
I0110 18:55:20.258766 20857 net.cpp:100] Creating Layer fc7
I0110 18:55:20.258770 20857 net.cpp:434] fc7 <- fc6
I0110 18:55:20.258776 20857 net.cpp:408] fc7 -> fc7
I0110 18:55:20.418974 20857 net.cpp:150] Setting up fc7
I0110 18:55:20.419023 20857 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:20.419026 20857 net.cpp:165] Memory required for data: 85802080
I0110 18:55:20.419036 20857 layer_factory.hpp:77] Creating layer relu7
I0110 18:55:20.419055 20857 net.cpp:100] Creating Layer relu7
I0110 18:55:20.419060 20857 net.cpp:434] relu7 <- fc7
I0110 18:55:20.419066 20857 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:55:20.419515 20857 net.cpp:150] Setting up relu7
I0110 18:55:20.419526 20857 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:20.419529 20857 net.cpp:165] Memory required for data: 85933152
I0110 18:55:20.419533 20857 layer_factory.hpp:77] Creating layer drop7
I0110 18:55:20.419539 20857 net.cpp:100] Creating Layer drop7
I0110 18:55:20.419543 20857 net.cpp:434] drop7 <- fc7
I0110 18:55:20.419550 20857 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:55:20.419579 20857 net.cpp:150] Setting up drop7
I0110 18:55:20.419585 20857 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:20.419589 20857 net.cpp:165] Memory required for data: 86064224
I0110 18:55:20.419591 20857 layer_factory.hpp:77] Creating layer fc8
I0110 18:55:20.419598 20857 net.cpp:100] Creating Layer fc8
I0110 18:55:20.419601 20857 net.cpp:434] fc8 <- fc7
I0110 18:55:20.419620 20857 net.cpp:408] fc8 -> fc8
I0110 18:55:20.419781 20857 net.cpp:150] Setting up fc8
I0110 18:55:20.419790 20857 net.cpp:157] Top shape: 8 1 (8)
I0110 18:55:20.419792 20857 net.cpp:165] Memory required for data: 86064256
I0110 18:55:20.419798 20857 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0110 18:55:20.419808 20857 net.cpp:100] Creating Layer fc8_fc8_0_split
I0110 18:55:20.419811 20857 net.cpp:434] fc8_fc8_0_split <- fc8
I0110 18:55:20.419816 20857 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0110 18:55:20.419823 20857 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0110 18:55:20.419857 20857 net.cpp:150] Setting up fc8_fc8_0_split
I0110 18:55:20.419862 20857 net.cpp:157] Top shape: 8 1 (8)
I0110 18:55:20.419867 20857 net.cpp:157] Top shape: 8 1 (8)
I0110 18:55:20.419868 20857 net.cpp:165] Memory required for data: 86064320
I0110 18:55:20.419872 20857 layer_factory.hpp:77] Creating layer accuracy
I0110 18:55:20.419878 20857 net.cpp:100] Creating Layer accuracy
I0110 18:55:20.419881 20857 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0110 18:55:20.419886 20857 net.cpp:434] accuracy <- label_data_0_split_0
I0110 18:55:20.419891 20857 net.cpp:408] accuracy -> accuracy
I0110 18:55:20.419899 20857 net.cpp:150] Setting up accuracy
I0110 18:55:20.419903 20857 net.cpp:157] Top shape: (1)
I0110 18:55:20.419906 20857 net.cpp:165] Memory required for data: 86064324
I0110 18:55:20.419909 20857 layer_factory.hpp:77] Creating layer loss
I0110 18:55:20.419914 20857 net.cpp:100] Creating Layer loss
I0110 18:55:20.419917 20857 net.cpp:434] loss <- fc8_fc8_0_split_1
I0110 18:55:20.419921 20857 net.cpp:434] loss <- label_data_0_split_1
I0110 18:55:20.419925 20857 net.cpp:408] loss -> loss
I0110 18:55:20.419932 20857 layer_factory.hpp:77] Creating layer loss
I0110 18:55:20.420156 20857 net.cpp:150] Setting up loss
I0110 18:55:20.420164 20857 net.cpp:157] Top shape: (1)
I0110 18:55:20.420167 20857 net.cpp:160]     with loss weight 1
I0110 18:55:20.420178 20857 net.cpp:165] Memory required for data: 86064328
I0110 18:55:20.420181 20857 net.cpp:226] loss needs backward computation.
I0110 18:55:20.420186 20857 net.cpp:228] accuracy does not need backward computation.
I0110 18:55:20.420191 20857 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0110 18:55:20.420193 20857 net.cpp:226] fc8 needs backward computation.
I0110 18:55:20.420197 20857 net.cpp:226] drop7 needs backward computation.
I0110 18:55:20.420199 20857 net.cpp:226] relu7 needs backward computation.
I0110 18:55:20.420202 20857 net.cpp:226] fc7 needs backward computation.
I0110 18:55:20.420205 20857 net.cpp:226] drop6 needs backward computation.
I0110 18:55:20.420208 20857 net.cpp:226] relu6 needs backward computation.
I0110 18:55:20.420212 20857 net.cpp:226] fc6 needs backward computation.
I0110 18:55:20.420215 20857 net.cpp:226] pool5 needs backward computation.
I0110 18:55:20.420218 20857 net.cpp:226] relu5 needs backward computation.
I0110 18:55:20.420222 20857 net.cpp:226] conv5 needs backward computation.
I0110 18:55:20.420225 20857 net.cpp:226] relu4 needs backward computation.
I0110 18:55:20.420228 20857 net.cpp:226] conv4 needs backward computation.
I0110 18:55:20.420233 20857 net.cpp:226] relu3 needs backward computation.
I0110 18:55:20.420236 20857 net.cpp:226] conv3 needs backward computation.
I0110 18:55:20.420240 20857 net.cpp:226] pool2 needs backward computation.
I0110 18:55:20.420243 20857 net.cpp:226] norm2 needs backward computation.
I0110 18:55:20.420248 20857 net.cpp:226] relu2 needs backward computation.
I0110 18:55:20.420250 20857 net.cpp:226] conv2 needs backward computation.
I0110 18:55:20.420253 20857 net.cpp:226] pool1 needs backward computation.
I0110 18:55:20.420256 20857 net.cpp:226] norm1 needs backward computation.
I0110 18:55:20.420260 20857 net.cpp:226] relu1 needs backward computation.
I0110 18:55:20.420264 20857 net.cpp:226] conv1 needs backward computation.
I0110 18:55:20.420267 20857 net.cpp:228] label_data_0_split does not need backward computation.
I0110 18:55:20.420271 20857 net.cpp:228] data does not need backward computation.
I0110 18:55:20.420279 20857 net.cpp:228] data does not need backward computation.
I0110 18:55:20.420284 20857 net.cpp:270] This network produces output accuracy
I0110 18:55:20.420286 20857 net.cpp:270] This network produces output loss
I0110 18:55:20.420305 20857 net.cpp:283] Network initialization done.
I0110 18:55:20.420378 20857 solver.cpp:60] Solver scaffolding done.
I0110 18:55:20.420915 20857 caffe.cpp:251] Starting Optimization
I0110 18:55:20.420920 20857 solver.cpp:279] Solving AlexNet
I0110 18:55:20.420924 20857 solver.cpp:280] Learning Rate Policy: step
I0110 18:55:20.422636 20857 solver.cpp:337] Iteration 0, Testing net (#0)
I0110 18:55:40.817131 20857 solver.cpp:386] Test interrupted.
I0110 18:55:40.977690 20857 solver.cpp:301] Optimization stopped early.
I0110 18:55:40.977713 20857 caffe.cpp:254] Optimization Done.
I0110 18:55:41.344909 20920 caffe.cpp:217] Using GPUs 0
I0110 18:55:41.345458 20920 caffe.cpp:222] GPU 0: GeForce 840M
I0110 18:55:41.557097 20920 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2383
test_interval: 4000
base_lr: 0.01
display: 200
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 12000
snapshot: 4000
snapshot_prefix: "models/2/caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "temp_net.prototxt"
train_state {
  level: 0
  stage: ""
}
I0110 18:55:41.557238 20920 solver.cpp:91] Creating training net from net file: temp_net.prototxt
I0110 18:55:41.557515 20920 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:55:41.557524 20920 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:55:41.557536 20920 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0110 18:55:41.557672 20920 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "train_loc.txt"
    batch_size: 16
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "label_list/train_label-2.txt"
    batch_size: 16
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:55:41.557760 20920 layer_factory.hpp:77] Creating layer data
I0110 18:55:41.557772 20920 net.cpp:100] Creating Layer data
I0110 18:55:41.557778 20920 net.cpp:408] data -> data
I0110 18:55:41.557798 20920 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: train_loc.txt
I0110 18:55:41.557837 20920 hdf5_data_layer.cpp:93] Number of HDF5 files: 38
I0110 18:55:41.558627 20920 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0110 18:55:41.899024 20920 net.cpp:150] Setting up data
I0110 18:55:41.899066 20920 net.cpp:157] Top shape: 16 3 256 256 (3145728)
I0110 18:55:41.899071 20920 net.cpp:165] Memory required for data: 12582912
I0110 18:55:41.899080 20920 layer_factory.hpp:77] Creating layer data
I0110 18:55:41.899093 20920 net.cpp:100] Creating Layer data
I0110 18:55:41.899098 20920 net.cpp:408] data -> label
I0110 18:55:41.899109 20920 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/train_label-2.txt
I0110 18:55:41.899137 20920 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:55:41.899415 20920 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0110 18:55:41.900331 20920 net.cpp:150] Setting up data
I0110 18:55:41.900355 20920 net.cpp:157] Top shape: 16 1 1 1 (16)
I0110 18:55:41.900359 20920 net.cpp:165] Memory required for data: 12582976
I0110 18:55:41.900364 20920 layer_factory.hpp:77] Creating layer conv1
I0110 18:55:41.900383 20920 net.cpp:100] Creating Layer conv1
I0110 18:55:41.900389 20920 net.cpp:434] conv1 <- data
I0110 18:55:41.900401 20920 net.cpp:408] conv1 -> conv1
I0110 18:55:42.095474 20920 net.cpp:150] Setting up conv1
I0110 18:55:42.095521 20920 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:55:42.095526 20920 net.cpp:165] Memory required for data: 36200512
I0110 18:55:42.095548 20920 layer_factory.hpp:77] Creating layer relu1
I0110 18:55:42.095559 20920 net.cpp:100] Creating Layer relu1
I0110 18:55:42.095563 20920 net.cpp:434] relu1 <- conv1
I0110 18:55:42.095569 20920 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:55:42.095734 20920 net.cpp:150] Setting up relu1
I0110 18:55:42.095746 20920 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:55:42.095749 20920 net.cpp:165] Memory required for data: 59818048
I0110 18:55:42.095752 20920 layer_factory.hpp:77] Creating layer norm1
I0110 18:55:42.095772 20920 net.cpp:100] Creating Layer norm1
I0110 18:55:42.095777 20920 net.cpp:434] norm1 <- conv1
I0110 18:55:42.095782 20920 net.cpp:408] norm1 -> norm1
I0110 18:55:42.096133 20920 net.cpp:150] Setting up norm1
I0110 18:55:42.096145 20920 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:55:42.096149 20920 net.cpp:165] Memory required for data: 83435584
I0110 18:55:42.096153 20920 layer_factory.hpp:77] Creating layer pool1
I0110 18:55:42.096159 20920 net.cpp:100] Creating Layer pool1
I0110 18:55:42.096163 20920 net.cpp:434] pool1 <- norm1
I0110 18:55:42.096168 20920 net.cpp:408] pool1 -> pool1
I0110 18:55:42.096205 20920 net.cpp:150] Setting up pool1
I0110 18:55:42.096213 20920 net.cpp:157] Top shape: 16 96 31 31 (1476096)
I0110 18:55:42.096216 20920 net.cpp:165] Memory required for data: 89339968
I0110 18:55:42.096220 20920 layer_factory.hpp:77] Creating layer conv2
I0110 18:55:42.096230 20920 net.cpp:100] Creating Layer conv2
I0110 18:55:42.096235 20920 net.cpp:434] conv2 <- pool1
I0110 18:55:42.096240 20920 net.cpp:408] conv2 -> conv2
I0110 18:55:42.101306 20920 net.cpp:150] Setting up conv2
I0110 18:55:42.101351 20920 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:55:42.101356 20920 net.cpp:165] Memory required for data: 105084992
I0110 18:55:42.101368 20920 layer_factory.hpp:77] Creating layer relu2
I0110 18:55:42.101385 20920 net.cpp:100] Creating Layer relu2
I0110 18:55:42.101390 20920 net.cpp:434] relu2 <- conv2
I0110 18:55:42.101397 20920 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:55:42.101722 20920 net.cpp:150] Setting up relu2
I0110 18:55:42.101732 20920 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:55:42.101735 20920 net.cpp:165] Memory required for data: 120830016
I0110 18:55:42.101739 20920 layer_factory.hpp:77] Creating layer norm2
I0110 18:55:42.101747 20920 net.cpp:100] Creating Layer norm2
I0110 18:55:42.101752 20920 net.cpp:434] norm2 <- conv2
I0110 18:55:42.101757 20920 net.cpp:408] norm2 -> norm2
I0110 18:55:42.101913 20920 net.cpp:150] Setting up norm2
I0110 18:55:42.101922 20920 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:55:42.101925 20920 net.cpp:165] Memory required for data: 136575040
I0110 18:55:42.101928 20920 layer_factory.hpp:77] Creating layer pool2
I0110 18:55:42.101934 20920 net.cpp:100] Creating Layer pool2
I0110 18:55:42.101938 20920 net.cpp:434] pool2 <- norm2
I0110 18:55:42.101943 20920 net.cpp:408] pool2 -> pool2
I0110 18:55:42.102272 20920 net.cpp:150] Setting up pool2
I0110 18:55:42.102283 20920 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:55:42.102285 20920 net.cpp:165] Memory required for data: 140261440
I0110 18:55:42.102289 20920 layer_factory.hpp:77] Creating layer conv3
I0110 18:55:42.102299 20920 net.cpp:100] Creating Layer conv3
I0110 18:55:42.102303 20920 net.cpp:434] conv3 <- pool2
I0110 18:55:42.102309 20920 net.cpp:408] conv3 -> conv3
I0110 18:55:42.112999 20920 net.cpp:150] Setting up conv3
I0110 18:55:42.113034 20920 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:42.113039 20920 net.cpp:165] Memory required for data: 145791040
I0110 18:55:42.113051 20920 layer_factory.hpp:77] Creating layer relu3
I0110 18:55:42.113060 20920 net.cpp:100] Creating Layer relu3
I0110 18:55:42.113065 20920 net.cpp:434] relu3 <- conv3
I0110 18:55:42.113071 20920 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:55:42.113226 20920 net.cpp:150] Setting up relu3
I0110 18:55:42.113242 20920 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:42.113246 20920 net.cpp:165] Memory required for data: 151320640
I0110 18:55:42.113250 20920 layer_factory.hpp:77] Creating layer conv4
I0110 18:55:42.113260 20920 net.cpp:100] Creating Layer conv4
I0110 18:55:42.113263 20920 net.cpp:434] conv4 <- conv3
I0110 18:55:42.113270 20920 net.cpp:408] conv4 -> conv4
I0110 18:55:42.121959 20920 net.cpp:150] Setting up conv4
I0110 18:55:42.121994 20920 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:42.121999 20920 net.cpp:165] Memory required for data: 156850240
I0110 18:55:42.122009 20920 layer_factory.hpp:77] Creating layer relu4
I0110 18:55:42.122028 20920 net.cpp:100] Creating Layer relu4
I0110 18:55:42.122032 20920 net.cpp:434] relu4 <- conv4
I0110 18:55:42.122040 20920 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:55:42.122191 20920 net.cpp:150] Setting up relu4
I0110 18:55:42.122200 20920 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:55:42.122203 20920 net.cpp:165] Memory required for data: 162379840
I0110 18:55:42.122207 20920 layer_factory.hpp:77] Creating layer conv5
I0110 18:55:42.122217 20920 net.cpp:100] Creating Layer conv5
I0110 18:55:42.122221 20920 net.cpp:434] conv5 <- conv4
I0110 18:55:42.122227 20920 net.cpp:408] conv5 -> conv5
I0110 18:55:42.128828 20920 net.cpp:150] Setting up conv5
I0110 18:55:42.128859 20920 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:55:42.128865 20920 net.cpp:165] Memory required for data: 166066240
I0110 18:55:42.128876 20920 layer_factory.hpp:77] Creating layer relu5
I0110 18:55:42.128885 20920 net.cpp:100] Creating Layer relu5
I0110 18:55:42.128890 20920 net.cpp:434] relu5 <- conv5
I0110 18:55:42.128896 20920 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:55:42.129053 20920 net.cpp:150] Setting up relu5
I0110 18:55:42.129062 20920 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:55:42.129066 20920 net.cpp:165] Memory required for data: 169752640
I0110 18:55:42.129070 20920 layer_factory.hpp:77] Creating layer pool5
I0110 18:55:42.129078 20920 net.cpp:100] Creating Layer pool5
I0110 18:55:42.129082 20920 net.cpp:434] pool5 <- conv5
I0110 18:55:42.129088 20920 net.cpp:408] pool5 -> pool5
I0110 18:55:42.129422 20920 net.cpp:150] Setting up pool5
I0110 18:55:42.129434 20920 net.cpp:157] Top shape: 16 256 7 7 (200704)
I0110 18:55:42.129438 20920 net.cpp:165] Memory required for data: 170555456
I0110 18:55:42.129441 20920 layer_factory.hpp:77] Creating layer fc6
I0110 18:55:42.129449 20920 net.cpp:100] Creating Layer fc6
I0110 18:55:42.129452 20920 net.cpp:434] fc6 <- pool5
I0110 18:55:42.129459 20920 net.cpp:408] fc6 -> fc6
I0110 18:55:42.617467 20920 net.cpp:150] Setting up fc6
I0110 18:55:42.617516 20920 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:42.617519 20920 net.cpp:165] Memory required for data: 170817600
I0110 18:55:42.617532 20920 layer_factory.hpp:77] Creating layer relu6
I0110 18:55:42.617542 20920 net.cpp:100] Creating Layer relu6
I0110 18:55:42.617547 20920 net.cpp:434] relu6 <- fc6
I0110 18:55:42.617554 20920 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:55:42.618032 20920 net.cpp:150] Setting up relu6
I0110 18:55:42.618046 20920 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:42.618048 20920 net.cpp:165] Memory required for data: 171079744
I0110 18:55:42.618052 20920 layer_factory.hpp:77] Creating layer drop6
I0110 18:55:42.618059 20920 net.cpp:100] Creating Layer drop6
I0110 18:55:42.618062 20920 net.cpp:434] drop6 <- fc6
I0110 18:55:42.618067 20920 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:55:42.618096 20920 net.cpp:150] Setting up drop6
I0110 18:55:42.618103 20920 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:42.618105 20920 net.cpp:165] Memory required for data: 171341888
I0110 18:55:42.618108 20920 layer_factory.hpp:77] Creating layer fc7
I0110 18:55:42.618116 20920 net.cpp:100] Creating Layer fc7
I0110 18:55:42.618120 20920 net.cpp:434] fc7 <- fc6
I0110 18:55:42.618125 20920 net.cpp:408] fc7 -> fc7
I0110 18:55:42.778568 20920 net.cpp:150] Setting up fc7
I0110 18:55:42.778622 20920 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:42.778627 20920 net.cpp:165] Memory required for data: 171604032
I0110 18:55:42.778637 20920 layer_factory.hpp:77] Creating layer relu7
I0110 18:55:42.778656 20920 net.cpp:100] Creating Layer relu7
I0110 18:55:42.778661 20920 net.cpp:434] relu7 <- fc7
I0110 18:55:42.778667 20920 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:55:42.778872 20920 net.cpp:150] Setting up relu7
I0110 18:55:42.778882 20920 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:42.778884 20920 net.cpp:165] Memory required for data: 171866176
I0110 18:55:42.778887 20920 layer_factory.hpp:77] Creating layer drop7
I0110 18:55:42.778904 20920 net.cpp:100] Creating Layer drop7
I0110 18:55:42.778908 20920 net.cpp:434] drop7 <- fc7
I0110 18:55:42.778913 20920 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:55:42.778939 20920 net.cpp:150] Setting up drop7
I0110 18:55:42.778944 20920 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:55:42.778946 20920 net.cpp:165] Memory required for data: 172128320
I0110 18:55:42.778950 20920 layer_factory.hpp:77] Creating layer fc8
I0110 18:55:42.778959 20920 net.cpp:100] Creating Layer fc8
I0110 18:55:42.778961 20920 net.cpp:434] fc8 <- fc7
I0110 18:55:42.778966 20920 net.cpp:408] fc8 -> fc8
I0110 18:55:42.779093 20920 net.cpp:150] Setting up fc8
I0110 18:55:42.779099 20920 net.cpp:157] Top shape: 16 1 (16)
I0110 18:55:42.779103 20920 net.cpp:165] Memory required for data: 172128384
I0110 18:55:42.779108 20920 layer_factory.hpp:77] Creating layer loss
I0110 18:55:42.779112 20920 net.cpp:100] Creating Layer loss
I0110 18:55:42.779116 20920 net.cpp:434] loss <- fc8
I0110 18:55:42.779120 20920 net.cpp:434] loss <- label
I0110 18:55:42.779127 20920 net.cpp:408] loss -> loss
I0110 18:55:42.779139 20920 layer_factory.hpp:77] Creating layer loss
I0110 18:55:42.779605 20920 net.cpp:150] Setting up loss
I0110 18:55:42.779616 20920 net.cpp:157] Top shape: (1)
I0110 18:55:42.779620 20920 net.cpp:160]     with loss weight 1
I0110 18:55:42.779640 20920 net.cpp:165] Memory required for data: 172128388
I0110 18:55:42.779644 20920 net.cpp:226] loss needs backward computation.
I0110 18:55:42.779650 20920 net.cpp:226] fc8 needs backward computation.
I0110 18:55:42.779654 20920 net.cpp:226] drop7 needs backward computation.
I0110 18:55:42.779656 20920 net.cpp:226] relu7 needs backward computation.
I0110 18:55:42.779659 20920 net.cpp:226] fc7 needs backward computation.
I0110 18:55:42.779670 20920 net.cpp:226] drop6 needs backward computation.
I0110 18:55:42.779675 20920 net.cpp:226] relu6 needs backward computation.
I0110 18:55:42.779677 20920 net.cpp:226] fc6 needs backward computation.
I0110 18:55:42.779680 20920 net.cpp:226] pool5 needs backward computation.
I0110 18:55:42.779685 20920 net.cpp:226] relu5 needs backward computation.
I0110 18:55:42.779687 20920 net.cpp:226] conv5 needs backward computation.
I0110 18:55:42.779691 20920 net.cpp:226] relu4 needs backward computation.
I0110 18:55:42.779695 20920 net.cpp:226] conv4 needs backward computation.
I0110 18:55:42.779697 20920 net.cpp:226] relu3 needs backward computation.
I0110 18:55:42.779700 20920 net.cpp:226] conv3 needs backward computation.
I0110 18:55:42.779705 20920 net.cpp:226] pool2 needs backward computation.
I0110 18:55:42.779707 20920 net.cpp:226] norm2 needs backward computation.
I0110 18:55:42.779711 20920 net.cpp:226] relu2 needs backward computation.
I0110 18:55:42.779714 20920 net.cpp:226] conv2 needs backward computation.
I0110 18:55:42.779717 20920 net.cpp:226] pool1 needs backward computation.
I0110 18:55:42.779721 20920 net.cpp:226] norm1 needs backward computation.
I0110 18:55:42.779724 20920 net.cpp:226] relu1 needs backward computation.
I0110 18:55:42.779727 20920 net.cpp:226] conv1 needs backward computation.
I0110 18:55:42.779731 20920 net.cpp:228] data does not need backward computation.
I0110 18:55:42.779733 20920 net.cpp:228] data does not need backward computation.
I0110 18:55:42.779736 20920 net.cpp:270] This network produces output loss
I0110 18:55:42.779750 20920 net.cpp:283] Network initialization done.
I0110 18:55:42.779995 20920 solver.cpp:181] Creating test net (#0) specified by net file: temp_net.prototxt
I0110 18:55:42.780025 20920 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:55:42.780030 20920 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:55:42.780167 20920 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "test_loc.txt"
    batch_size: 8
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "label_list/test_label-2.txt"
    batch_size: 8
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:55:42.780261 20920 layer_factory.hpp:77] Creating layer data
I0110 18:55:42.780269 20920 net.cpp:100] Creating Layer data
I0110 18:55:42.780273 20920 net.cpp:408] data -> data
I0110 18:55:42.780280 20920 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: test_loc.txt
I0110 18:55:42.780299 20920 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0110 18:55:43.096782 20920 net.cpp:150] Setting up data
I0110 18:55:43.096827 20920 net.cpp:157] Top shape: 8 3 256 256 (1572864)
I0110 18:55:43.096834 20920 net.cpp:165] Memory required for data: 6291456
I0110 18:55:43.096844 20920 layer_factory.hpp:77] Creating layer data
I0110 18:55:43.096860 20920 net.cpp:100] Creating Layer data
I0110 18:55:43.096869 20920 net.cpp:408] data -> label
I0110 18:55:43.096886 20920 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/test_label-2.txt
I0110 18:55:43.096925 20920 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:55:43.098081 20920 net.cpp:150] Setting up data
I0110 18:55:43.098099 20920 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:55:43.098104 20920 net.cpp:165] Memory required for data: 6291488
I0110 18:55:43.098109 20920 layer_factory.hpp:77] Creating layer label_data_0_split
I0110 18:55:43.098119 20920 net.cpp:100] Creating Layer label_data_0_split
I0110 18:55:43.098125 20920 net.cpp:434] label_data_0_split <- label
I0110 18:55:43.098132 20920 net.cpp:408] label_data_0_split -> label_data_0_split_0
I0110 18:55:43.098141 20920 net.cpp:408] label_data_0_split -> label_data_0_split_1
I0110 18:55:43.098191 20920 net.cpp:150] Setting up label_data_0_split
I0110 18:55:43.098198 20920 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:55:43.098202 20920 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:55:43.098206 20920 net.cpp:165] Memory required for data: 6291552
I0110 18:55:43.098209 20920 layer_factory.hpp:77] Creating layer conv1
I0110 18:55:43.098222 20920 net.cpp:100] Creating Layer conv1
I0110 18:55:43.098227 20920 net.cpp:434] conv1 <- data
I0110 18:55:43.098232 20920 net.cpp:408] conv1 -> conv1
I0110 18:55:43.099694 20920 net.cpp:150] Setting up conv1
I0110 18:55:43.099711 20920 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:55:43.099716 20920 net.cpp:165] Memory required for data: 18100320
I0110 18:55:43.099727 20920 layer_factory.hpp:77] Creating layer relu1
I0110 18:55:43.099736 20920 net.cpp:100] Creating Layer relu1
I0110 18:55:43.099740 20920 net.cpp:434] relu1 <- conv1
I0110 18:55:43.099746 20920 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:55:43.100131 20920 net.cpp:150] Setting up relu1
I0110 18:55:43.100144 20920 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:55:43.100155 20920 net.cpp:165] Memory required for data: 29909088
I0110 18:55:43.100159 20920 layer_factory.hpp:77] Creating layer norm1
I0110 18:55:43.100168 20920 net.cpp:100] Creating Layer norm1
I0110 18:55:43.100172 20920 net.cpp:434] norm1 <- conv1
I0110 18:55:43.100178 20920 net.cpp:408] norm1 -> norm1
I0110 18:55:43.100368 20920 net.cpp:150] Setting up norm1
I0110 18:55:43.100378 20920 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:55:43.100381 20920 net.cpp:165] Memory required for data: 41717856
I0110 18:55:43.100385 20920 layer_factory.hpp:77] Creating layer pool1
I0110 18:55:43.100391 20920 net.cpp:100] Creating Layer pool1
I0110 18:55:43.100406 20920 net.cpp:434] pool1 <- norm1
I0110 18:55:43.100412 20920 net.cpp:408] pool1 -> pool1
I0110 18:55:43.100450 20920 net.cpp:150] Setting up pool1
I0110 18:55:43.100457 20920 net.cpp:157] Top shape: 8 96 31 31 (738048)
I0110 18:55:43.100461 20920 net.cpp:165] Memory required for data: 44670048
I0110 18:55:43.100464 20920 layer_factory.hpp:77] Creating layer conv2
I0110 18:55:43.100474 20920 net.cpp:100] Creating Layer conv2
I0110 18:55:43.100478 20920 net.cpp:434] conv2 <- pool1
I0110 18:55:43.100483 20920 net.cpp:408] conv2 -> conv2
I0110 18:55:43.105931 20920 net.cpp:150] Setting up conv2
I0110 18:55:43.105953 20920 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:55:43.105958 20920 net.cpp:165] Memory required for data: 52542560
I0110 18:55:43.105968 20920 layer_factory.hpp:77] Creating layer relu2
I0110 18:55:43.105978 20920 net.cpp:100] Creating Layer relu2
I0110 18:55:43.105983 20920 net.cpp:434] relu2 <- conv2
I0110 18:55:43.105988 20920 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:55:43.106343 20920 net.cpp:150] Setting up relu2
I0110 18:55:43.106356 20920 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:55:43.106360 20920 net.cpp:165] Memory required for data: 60415072
I0110 18:55:43.106364 20920 layer_factory.hpp:77] Creating layer norm2
I0110 18:55:43.106371 20920 net.cpp:100] Creating Layer norm2
I0110 18:55:43.106374 20920 net.cpp:434] norm2 <- conv2
I0110 18:55:43.106380 20920 net.cpp:408] norm2 -> norm2
I0110 18:55:43.106564 20920 net.cpp:150] Setting up norm2
I0110 18:55:43.106573 20920 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:55:43.106577 20920 net.cpp:165] Memory required for data: 68287584
I0110 18:55:43.106580 20920 layer_factory.hpp:77] Creating layer pool2
I0110 18:55:43.106587 20920 net.cpp:100] Creating Layer pool2
I0110 18:55:43.106591 20920 net.cpp:434] pool2 <- norm2
I0110 18:55:43.106596 20920 net.cpp:408] pool2 -> pool2
I0110 18:55:43.106958 20920 net.cpp:150] Setting up pool2
I0110 18:55:43.106971 20920 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:55:43.106974 20920 net.cpp:165] Memory required for data: 70130784
I0110 18:55:43.106978 20920 layer_factory.hpp:77] Creating layer conv3
I0110 18:55:43.106988 20920 net.cpp:100] Creating Layer conv3
I0110 18:55:43.106992 20920 net.cpp:434] conv3 <- pool2
I0110 18:55:43.106999 20920 net.cpp:408] conv3 -> conv3
I0110 18:55:43.118206 20920 net.cpp:150] Setting up conv3
I0110 18:55:43.118244 20920 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:43.118252 20920 net.cpp:165] Memory required for data: 72895584
I0110 18:55:43.118266 20920 layer_factory.hpp:77] Creating layer relu3
I0110 18:55:43.118278 20920 net.cpp:100] Creating Layer relu3
I0110 18:55:43.118284 20920 net.cpp:434] relu3 <- conv3
I0110 18:55:43.118293 20920 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:55:43.118669 20920 net.cpp:150] Setting up relu3
I0110 18:55:43.118682 20920 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:43.118686 20920 net.cpp:165] Memory required for data: 75660384
I0110 18:55:43.118690 20920 layer_factory.hpp:77] Creating layer conv4
I0110 18:55:43.118702 20920 net.cpp:100] Creating Layer conv4
I0110 18:55:43.118706 20920 net.cpp:434] conv4 <- conv3
I0110 18:55:43.118713 20920 net.cpp:408] conv4 -> conv4
I0110 18:55:43.128346 20920 net.cpp:150] Setting up conv4
I0110 18:55:43.128382 20920 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:43.128392 20920 net.cpp:165] Memory required for data: 78425184
I0110 18:55:43.128402 20920 layer_factory.hpp:77] Creating layer relu4
I0110 18:55:43.128412 20920 net.cpp:100] Creating Layer relu4
I0110 18:55:43.128418 20920 net.cpp:434] relu4 <- conv4
I0110 18:55:43.128424 20920 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:55:43.128600 20920 net.cpp:150] Setting up relu4
I0110 18:55:43.128612 20920 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:55:43.128614 20920 net.cpp:165] Memory required for data: 81189984
I0110 18:55:43.128618 20920 layer_factory.hpp:77] Creating layer conv5
I0110 18:55:43.128629 20920 net.cpp:100] Creating Layer conv5
I0110 18:55:43.128643 20920 net.cpp:434] conv5 <- conv4
I0110 18:55:43.128649 20920 net.cpp:408] conv5 -> conv5
I0110 18:55:43.135594 20920 net.cpp:150] Setting up conv5
I0110 18:55:43.135627 20920 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:55:43.135632 20920 net.cpp:165] Memory required for data: 83033184
I0110 18:55:43.135644 20920 layer_factory.hpp:77] Creating layer relu5
I0110 18:55:43.135658 20920 net.cpp:100] Creating Layer relu5
I0110 18:55:43.135669 20920 net.cpp:434] relu5 <- conv5
I0110 18:55:43.135677 20920 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:55:43.135848 20920 net.cpp:150] Setting up relu5
I0110 18:55:43.135857 20920 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:55:43.135860 20920 net.cpp:165] Memory required for data: 84876384
I0110 18:55:43.135864 20920 layer_factory.hpp:77] Creating layer pool5
I0110 18:55:43.135872 20920 net.cpp:100] Creating Layer pool5
I0110 18:55:43.135876 20920 net.cpp:434] pool5 <- conv5
I0110 18:55:43.135882 20920 net.cpp:408] pool5 -> pool5
I0110 18:55:43.136627 20920 net.cpp:150] Setting up pool5
I0110 18:55:43.136641 20920 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0110 18:55:43.136644 20920 net.cpp:165] Memory required for data: 85277792
I0110 18:55:43.136647 20920 layer_factory.hpp:77] Creating layer fc6
I0110 18:55:43.136657 20920 net.cpp:100] Creating Layer fc6
I0110 18:55:43.136662 20920 net.cpp:434] fc6 <- pool5
I0110 18:55:43.136667 20920 net.cpp:408] fc6 -> fc6
I0110 18:55:43.632084 20920 net.cpp:150] Setting up fc6
I0110 18:55:43.632133 20920 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:43.632136 20920 net.cpp:165] Memory required for data: 85408864
I0110 18:55:43.632148 20920 layer_factory.hpp:77] Creating layer relu6
I0110 18:55:43.632156 20920 net.cpp:100] Creating Layer relu6
I0110 18:55:43.632161 20920 net.cpp:434] relu6 <- fc6
I0110 18:55:43.632169 20920 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:55:43.632383 20920 net.cpp:150] Setting up relu6
I0110 18:55:43.632392 20920 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:43.632395 20920 net.cpp:165] Memory required for data: 85539936
I0110 18:55:43.632398 20920 layer_factory.hpp:77] Creating layer drop6
I0110 18:55:43.632406 20920 net.cpp:100] Creating Layer drop6
I0110 18:55:43.632410 20920 net.cpp:434] drop6 <- fc6
I0110 18:55:43.632414 20920 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:55:43.632441 20920 net.cpp:150] Setting up drop6
I0110 18:55:43.632446 20920 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:43.632448 20920 net.cpp:165] Memory required for data: 85671008
I0110 18:55:43.632452 20920 layer_factory.hpp:77] Creating layer fc7
I0110 18:55:43.632458 20920 net.cpp:100] Creating Layer fc7
I0110 18:55:43.632462 20920 net.cpp:434] fc7 <- fc6
I0110 18:55:43.632467 20920 net.cpp:408] fc7 -> fc7
I0110 18:55:43.792424 20920 net.cpp:150] Setting up fc7
I0110 18:55:43.792471 20920 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:43.792475 20920 net.cpp:165] Memory required for data: 85802080
I0110 18:55:43.792485 20920 layer_factory.hpp:77] Creating layer relu7
I0110 18:55:43.792505 20920 net.cpp:100] Creating Layer relu7
I0110 18:55:43.792510 20920 net.cpp:434] relu7 <- fc7
I0110 18:55:43.792516 20920 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:55:43.795397 20920 net.cpp:150] Setting up relu7
I0110 18:55:43.795409 20920 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:43.795413 20920 net.cpp:165] Memory required for data: 85933152
I0110 18:55:43.795423 20920 layer_factory.hpp:77] Creating layer drop7
I0110 18:55:43.795431 20920 net.cpp:100] Creating Layer drop7
I0110 18:55:43.795435 20920 net.cpp:434] drop7 <- fc7
I0110 18:55:43.795441 20920 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:55:43.795470 20920 net.cpp:150] Setting up drop7
I0110 18:55:43.795476 20920 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:55:43.795480 20920 net.cpp:165] Memory required for data: 86064224
I0110 18:55:43.795482 20920 layer_factory.hpp:77] Creating layer fc8
I0110 18:55:43.795490 20920 net.cpp:100] Creating Layer fc8
I0110 18:55:43.795493 20920 net.cpp:434] fc8 <- fc7
I0110 18:55:43.795508 20920 net.cpp:408] fc8 -> fc8
I0110 18:55:43.795644 20920 net.cpp:150] Setting up fc8
I0110 18:55:43.795650 20920 net.cpp:157] Top shape: 8 1 (8)
I0110 18:55:43.795653 20920 net.cpp:165] Memory required for data: 86064256
I0110 18:55:43.795660 20920 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0110 18:55:43.795671 20920 net.cpp:100] Creating Layer fc8_fc8_0_split
I0110 18:55:43.795675 20920 net.cpp:434] fc8_fc8_0_split <- fc8
I0110 18:55:43.795681 20920 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0110 18:55:43.795687 20920 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0110 18:55:43.795722 20920 net.cpp:150] Setting up fc8_fc8_0_split
I0110 18:55:43.795728 20920 net.cpp:157] Top shape: 8 1 (8)
I0110 18:55:43.795732 20920 net.cpp:157] Top shape: 8 1 (8)
I0110 18:55:43.795735 20920 net.cpp:165] Memory required for data: 86064320
I0110 18:55:43.795738 20920 layer_factory.hpp:77] Creating layer accuracy
I0110 18:55:43.795743 20920 net.cpp:100] Creating Layer accuracy
I0110 18:55:43.795747 20920 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0110 18:55:43.795752 20920 net.cpp:434] accuracy <- label_data_0_split_0
I0110 18:55:43.795758 20920 net.cpp:408] accuracy -> accuracy
I0110 18:55:43.795764 20920 net.cpp:150] Setting up accuracy
I0110 18:55:43.795768 20920 net.cpp:157] Top shape: (1)
I0110 18:55:43.795771 20920 net.cpp:165] Memory required for data: 86064324
I0110 18:55:43.795774 20920 layer_factory.hpp:77] Creating layer loss
I0110 18:55:43.795779 20920 net.cpp:100] Creating Layer loss
I0110 18:55:43.795783 20920 net.cpp:434] loss <- fc8_fc8_0_split_1
I0110 18:55:43.795786 20920 net.cpp:434] loss <- label_data_0_split_1
I0110 18:55:43.795790 20920 net.cpp:408] loss -> loss
I0110 18:55:43.795797 20920 layer_factory.hpp:77] Creating layer loss
I0110 18:55:43.796023 20920 net.cpp:150] Setting up loss
I0110 18:55:43.796032 20920 net.cpp:157] Top shape: (1)
I0110 18:55:43.796036 20920 net.cpp:160]     with loss weight 1
I0110 18:55:43.796046 20920 net.cpp:165] Memory required for data: 86064328
I0110 18:55:43.796048 20920 net.cpp:226] loss needs backward computation.
I0110 18:55:43.796052 20920 net.cpp:228] accuracy does not need backward computation.
I0110 18:55:43.796056 20920 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0110 18:55:43.796059 20920 net.cpp:226] fc8 needs backward computation.
I0110 18:55:43.796062 20920 net.cpp:226] drop7 needs backward computation.
I0110 18:55:43.796066 20920 net.cpp:226] relu7 needs backward computation.
I0110 18:55:43.796068 20920 net.cpp:226] fc7 needs backward computation.
I0110 18:55:43.796072 20920 net.cpp:226] drop6 needs backward computation.
I0110 18:55:43.796074 20920 net.cpp:226] relu6 needs backward computation.
I0110 18:55:43.796077 20920 net.cpp:226] fc6 needs backward computation.
I0110 18:55:43.796080 20920 net.cpp:226] pool5 needs backward computation.
I0110 18:55:43.796084 20920 net.cpp:226] relu5 needs backward computation.
I0110 18:55:43.796087 20920 net.cpp:226] conv5 needs backward computation.
I0110 18:55:43.796090 20920 net.cpp:226] relu4 needs backward computation.
I0110 18:55:43.796093 20920 net.cpp:226] conv4 needs backward computation.
I0110 18:55:43.796097 20920 net.cpp:226] relu3 needs backward computation.
I0110 18:55:43.796099 20920 net.cpp:226] conv3 needs backward computation.
I0110 18:55:43.796103 20920 net.cpp:226] pool2 needs backward computation.
I0110 18:55:43.796109 20920 net.cpp:226] norm2 needs backward computation.
I0110 18:55:43.796114 20920 net.cpp:226] relu2 needs backward computation.
I0110 18:55:43.796118 20920 net.cpp:226] conv2 needs backward computation.
I0110 18:55:43.796120 20920 net.cpp:226] pool1 needs backward computation.
I0110 18:55:43.796123 20920 net.cpp:226] norm1 needs backward computation.
I0110 18:55:43.796128 20920 net.cpp:226] relu1 needs backward computation.
I0110 18:55:43.796130 20920 net.cpp:226] conv1 needs backward computation.
I0110 18:55:43.796133 20920 net.cpp:228] label_data_0_split does not need backward computation.
I0110 18:55:43.796138 20920 net.cpp:228] data does not need backward computation.
I0110 18:55:43.796145 20920 net.cpp:228] data does not need backward computation.
I0110 18:55:43.796149 20920 net.cpp:270] This network produces output accuracy
I0110 18:55:43.796151 20920 net.cpp:270] This network produces output loss
I0110 18:55:43.796167 20920 net.cpp:283] Network initialization done.
I0110 18:55:43.796237 20920 solver.cpp:60] Solver scaffolding done.
I0110 18:55:43.796746 20920 caffe.cpp:251] Starting Optimization
I0110 18:55:43.796751 20920 solver.cpp:279] Solving AlexNet
I0110 18:55:43.796754 20920 solver.cpp:280] Learning Rate Policy: step
I0110 18:55:43.798498 20920 solver.cpp:337] Iteration 0, Testing net (#0)
I0110 18:56:37.068457 20920 solver.cpp:386] Test interrupted.
I0110 18:56:37.068531 20920 solver.cpp:301] Optimization stopped early.
I0110 18:56:37.068536 20920 caffe.cpp:254] Optimization Done.
I0110 18:56:37.436203 20959 caffe.cpp:217] Using GPUs 0
I0110 18:56:37.436722 20959 caffe.cpp:222] GPU 0: GeForce 840M
I0110 18:56:37.638407 20959 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2383
test_interval: 4000
base_lr: 0.01
display: 200
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 12000
snapshot: 4000
snapshot_prefix: "models/3/caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "temp_net.prototxt"
train_state {
  level: 0
  stage: ""
}
I0110 18:56:37.638550 20959 solver.cpp:91] Creating training net from net file: temp_net.prototxt
I0110 18:56:37.638815 20959 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:56:37.638825 20959 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:56:37.638836 20959 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0110 18:56:37.638972 20959 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "train_loc.txt"
    batch_size: 16
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "label_list/train_label-3.txt"
    batch_size: 16
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:56:37.639061 20959 layer_factory.hpp:77] Creating layer data
I0110 18:56:37.639075 20959 net.cpp:100] Creating Layer data
I0110 18:56:37.639081 20959 net.cpp:408] data -> data
I0110 18:56:37.639101 20959 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: train_loc.txt
I0110 18:56:37.639138 20959 hdf5_data_layer.cpp:93] Number of HDF5 files: 38
I0110 18:56:37.639963 20959 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0110 18:56:37.968515 20959 net.cpp:150] Setting up data
I0110 18:56:37.968561 20959 net.cpp:157] Top shape: 16 3 256 256 (3145728)
I0110 18:56:37.968571 20959 net.cpp:165] Memory required for data: 12582912
I0110 18:56:37.968595 20959 layer_factory.hpp:77] Creating layer data
I0110 18:56:37.968612 20959 net.cpp:100] Creating Layer data
I0110 18:56:37.968618 20959 net.cpp:408] data -> label
I0110 18:56:37.968631 20959 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/train_label-3.txt
I0110 18:56:37.968659 20959 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:56:37.968987 20959 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0110 18:56:37.972184 20959 net.cpp:150] Setting up data
I0110 18:56:37.972204 20959 net.cpp:157] Top shape: 16 1 1 1 (16)
I0110 18:56:37.972209 20959 net.cpp:165] Memory required for data: 12582976
I0110 18:56:37.972214 20959 layer_factory.hpp:77] Creating layer conv1
I0110 18:56:37.972232 20959 net.cpp:100] Creating Layer conv1
I0110 18:56:37.972239 20959 net.cpp:434] conv1 <- data
I0110 18:56:37.972250 20959 net.cpp:408] conv1 -> conv1
I0110 18:56:38.169219 20959 net.cpp:150] Setting up conv1
I0110 18:56:38.169257 20959 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:56:38.169263 20959 net.cpp:165] Memory required for data: 36200512
I0110 18:56:38.169288 20959 layer_factory.hpp:77] Creating layer relu1
I0110 18:56:38.169301 20959 net.cpp:100] Creating Layer relu1
I0110 18:56:38.169306 20959 net.cpp:434] relu1 <- conv1
I0110 18:56:38.169312 20959 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:56:38.169472 20959 net.cpp:150] Setting up relu1
I0110 18:56:38.169482 20959 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:56:38.169486 20959 net.cpp:165] Memory required for data: 59818048
I0110 18:56:38.169489 20959 layer_factory.hpp:77] Creating layer norm1
I0110 18:56:38.169512 20959 net.cpp:100] Creating Layer norm1
I0110 18:56:38.169517 20959 net.cpp:434] norm1 <- conv1
I0110 18:56:38.169522 20959 net.cpp:408] norm1 -> norm1
I0110 18:56:38.169875 20959 net.cpp:150] Setting up norm1
I0110 18:56:38.169888 20959 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:56:38.169891 20959 net.cpp:165] Memory required for data: 83435584
I0110 18:56:38.169894 20959 layer_factory.hpp:77] Creating layer pool1
I0110 18:56:38.169901 20959 net.cpp:100] Creating Layer pool1
I0110 18:56:38.169904 20959 net.cpp:434] pool1 <- norm1
I0110 18:56:38.169910 20959 net.cpp:408] pool1 -> pool1
I0110 18:56:38.169948 20959 net.cpp:150] Setting up pool1
I0110 18:56:38.169955 20959 net.cpp:157] Top shape: 16 96 31 31 (1476096)
I0110 18:56:38.169960 20959 net.cpp:165] Memory required for data: 89339968
I0110 18:56:38.169962 20959 layer_factory.hpp:77] Creating layer conv2
I0110 18:56:38.169973 20959 net.cpp:100] Creating Layer conv2
I0110 18:56:38.169977 20959 net.cpp:434] conv2 <- pool1
I0110 18:56:38.169982 20959 net.cpp:408] conv2 -> conv2
I0110 18:56:38.174963 20959 net.cpp:150] Setting up conv2
I0110 18:56:38.174994 20959 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:56:38.174998 20959 net.cpp:165] Memory required for data: 105084992
I0110 18:56:38.175010 20959 layer_factory.hpp:77] Creating layer relu2
I0110 18:56:38.175019 20959 net.cpp:100] Creating Layer relu2
I0110 18:56:38.175024 20959 net.cpp:434] relu2 <- conv2
I0110 18:56:38.175029 20959 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:56:38.175356 20959 net.cpp:150] Setting up relu2
I0110 18:56:38.175367 20959 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:56:38.175371 20959 net.cpp:165] Memory required for data: 120830016
I0110 18:56:38.175374 20959 layer_factory.hpp:77] Creating layer norm2
I0110 18:56:38.175382 20959 net.cpp:100] Creating Layer norm2
I0110 18:56:38.175386 20959 net.cpp:434] norm2 <- conv2
I0110 18:56:38.175391 20959 net.cpp:408] norm2 -> norm2
I0110 18:56:38.175550 20959 net.cpp:150] Setting up norm2
I0110 18:56:38.175559 20959 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:56:38.175564 20959 net.cpp:165] Memory required for data: 136575040
I0110 18:56:38.175566 20959 layer_factory.hpp:77] Creating layer pool2
I0110 18:56:38.175572 20959 net.cpp:100] Creating Layer pool2
I0110 18:56:38.175576 20959 net.cpp:434] pool2 <- norm2
I0110 18:56:38.175580 20959 net.cpp:408] pool2 -> pool2
I0110 18:56:38.175923 20959 net.cpp:150] Setting up pool2
I0110 18:56:38.175935 20959 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:56:38.175940 20959 net.cpp:165] Memory required for data: 140261440
I0110 18:56:38.175943 20959 layer_factory.hpp:77] Creating layer conv3
I0110 18:56:38.175953 20959 net.cpp:100] Creating Layer conv3
I0110 18:56:38.175957 20959 net.cpp:434] conv3 <- pool2
I0110 18:56:38.175962 20959 net.cpp:408] conv3 -> conv3
I0110 18:56:38.185866 20959 net.cpp:150] Setting up conv3
I0110 18:56:38.185904 20959 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:56:38.185907 20959 net.cpp:165] Memory required for data: 145791040
I0110 18:56:38.185919 20959 layer_factory.hpp:77] Creating layer relu3
I0110 18:56:38.185927 20959 net.cpp:100] Creating Layer relu3
I0110 18:56:38.185932 20959 net.cpp:434] relu3 <- conv3
I0110 18:56:38.185938 20959 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:56:38.186080 20959 net.cpp:150] Setting up relu3
I0110 18:56:38.186089 20959 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:56:38.186094 20959 net.cpp:165] Memory required for data: 151320640
I0110 18:56:38.186096 20959 layer_factory.hpp:77] Creating layer conv4
I0110 18:56:38.186106 20959 net.cpp:100] Creating Layer conv4
I0110 18:56:38.186110 20959 net.cpp:434] conv4 <- conv3
I0110 18:56:38.186115 20959 net.cpp:408] conv4 -> conv4
I0110 18:56:38.194644 20959 net.cpp:150] Setting up conv4
I0110 18:56:38.194681 20959 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:56:38.194685 20959 net.cpp:165] Memory required for data: 156850240
I0110 18:56:38.194694 20959 layer_factory.hpp:77] Creating layer relu4
I0110 18:56:38.194716 20959 net.cpp:100] Creating Layer relu4
I0110 18:56:38.194720 20959 net.cpp:434] relu4 <- conv4
I0110 18:56:38.194727 20959 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:56:38.194867 20959 net.cpp:150] Setting up relu4
I0110 18:56:38.194876 20959 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:56:38.194880 20959 net.cpp:165] Memory required for data: 162379840
I0110 18:56:38.194883 20959 layer_factory.hpp:77] Creating layer conv5
I0110 18:56:38.194893 20959 net.cpp:100] Creating Layer conv5
I0110 18:56:38.194897 20959 net.cpp:434] conv5 <- conv4
I0110 18:56:38.194902 20959 net.cpp:408] conv5 -> conv5
I0110 18:56:38.201367 20959 net.cpp:150] Setting up conv5
I0110 18:56:38.201396 20959 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:56:38.201400 20959 net.cpp:165] Memory required for data: 166066240
I0110 18:56:38.201412 20959 layer_factory.hpp:77] Creating layer relu5
I0110 18:56:38.201421 20959 net.cpp:100] Creating Layer relu5
I0110 18:56:38.201426 20959 net.cpp:434] relu5 <- conv5
I0110 18:56:38.201431 20959 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:56:38.201573 20959 net.cpp:150] Setting up relu5
I0110 18:56:38.201582 20959 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:56:38.201586 20959 net.cpp:165] Memory required for data: 169752640
I0110 18:56:38.201589 20959 layer_factory.hpp:77] Creating layer pool5
I0110 18:56:38.201597 20959 net.cpp:100] Creating Layer pool5
I0110 18:56:38.201601 20959 net.cpp:434] pool5 <- conv5
I0110 18:56:38.201607 20959 net.cpp:408] pool5 -> pool5
I0110 18:56:38.201930 20959 net.cpp:150] Setting up pool5
I0110 18:56:38.201942 20959 net.cpp:157] Top shape: 16 256 7 7 (200704)
I0110 18:56:38.201946 20959 net.cpp:165] Memory required for data: 170555456
I0110 18:56:38.201949 20959 layer_factory.hpp:77] Creating layer fc6
I0110 18:56:38.201956 20959 net.cpp:100] Creating Layer fc6
I0110 18:56:38.201959 20959 net.cpp:434] fc6 <- pool5
I0110 18:56:38.201966 20959 net.cpp:408] fc6 -> fc6
I0110 18:56:38.692440 20959 net.cpp:150] Setting up fc6
I0110 18:56:38.692486 20959 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:56:38.692492 20959 net.cpp:165] Memory required for data: 170817600
I0110 18:56:38.692504 20959 layer_factory.hpp:77] Creating layer relu6
I0110 18:56:38.692517 20959 net.cpp:100] Creating Layer relu6
I0110 18:56:38.692523 20959 net.cpp:434] relu6 <- fc6
I0110 18:56:38.692531 20959 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:56:38.692975 20959 net.cpp:150] Setting up relu6
I0110 18:56:38.692987 20959 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:56:38.692991 20959 net.cpp:165] Memory required for data: 171079744
I0110 18:56:38.692996 20959 layer_factory.hpp:77] Creating layer drop6
I0110 18:56:38.693001 20959 net.cpp:100] Creating Layer drop6
I0110 18:56:38.693006 20959 net.cpp:434] drop6 <- fc6
I0110 18:56:38.693011 20959 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:56:38.693037 20959 net.cpp:150] Setting up drop6
I0110 18:56:38.693043 20959 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:56:38.693048 20959 net.cpp:165] Memory required for data: 171341888
I0110 18:56:38.693050 20959 layer_factory.hpp:77] Creating layer fc7
I0110 18:56:38.693058 20959 net.cpp:100] Creating Layer fc7
I0110 18:56:38.693060 20959 net.cpp:434] fc7 <- fc6
I0110 18:56:38.693065 20959 net.cpp:408] fc7 -> fc7
I0110 18:56:38.853041 20959 net.cpp:150] Setting up fc7
I0110 18:56:38.853081 20959 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:56:38.853087 20959 net.cpp:165] Memory required for data: 171604032
I0110 18:56:38.853097 20959 layer_factory.hpp:77] Creating layer relu7
I0110 18:56:38.853106 20959 net.cpp:100] Creating Layer relu7
I0110 18:56:38.853111 20959 net.cpp:434] relu7 <- fc7
I0110 18:56:38.853117 20959 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:56:38.853308 20959 net.cpp:150] Setting up relu7
I0110 18:56:38.853318 20959 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:56:38.853322 20959 net.cpp:165] Memory required for data: 171866176
I0110 18:56:38.853324 20959 layer_factory.hpp:77] Creating layer drop7
I0110 18:56:38.853345 20959 net.cpp:100] Creating Layer drop7
I0110 18:56:38.853348 20959 net.cpp:434] drop7 <- fc7
I0110 18:56:38.853353 20959 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:56:38.853376 20959 net.cpp:150] Setting up drop7
I0110 18:56:38.853382 20959 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:56:38.853385 20959 net.cpp:165] Memory required for data: 172128320
I0110 18:56:38.853389 20959 layer_factory.hpp:77] Creating layer fc8
I0110 18:56:38.853395 20959 net.cpp:100] Creating Layer fc8
I0110 18:56:38.853399 20959 net.cpp:434] fc8 <- fc7
I0110 18:56:38.853404 20959 net.cpp:408] fc8 -> fc8
I0110 18:56:38.853521 20959 net.cpp:150] Setting up fc8
I0110 18:56:38.853528 20959 net.cpp:157] Top shape: 16 1 (16)
I0110 18:56:38.853530 20959 net.cpp:165] Memory required for data: 172128384
I0110 18:56:38.853535 20959 layer_factory.hpp:77] Creating layer loss
I0110 18:56:38.853540 20959 net.cpp:100] Creating Layer loss
I0110 18:56:38.853544 20959 net.cpp:434] loss <- fc8
I0110 18:56:38.853548 20959 net.cpp:434] loss <- label
I0110 18:56:38.853554 20959 net.cpp:408] loss -> loss
I0110 18:56:38.853565 20959 layer_factory.hpp:77] Creating layer loss
I0110 18:56:38.854013 20959 net.cpp:150] Setting up loss
I0110 18:56:38.854024 20959 net.cpp:157] Top shape: (1)
I0110 18:56:38.854027 20959 net.cpp:160]     with loss weight 1
I0110 18:56:38.854050 20959 net.cpp:165] Memory required for data: 172128388
I0110 18:56:38.854054 20959 net.cpp:226] loss needs backward computation.
I0110 18:56:38.854061 20959 net.cpp:226] fc8 needs backward computation.
I0110 18:56:38.854064 20959 net.cpp:226] drop7 needs backward computation.
I0110 18:56:38.854068 20959 net.cpp:226] relu7 needs backward computation.
I0110 18:56:38.854070 20959 net.cpp:226] fc7 needs backward computation.
I0110 18:56:38.854074 20959 net.cpp:226] drop6 needs backward computation.
I0110 18:56:38.854076 20959 net.cpp:226] relu6 needs backward computation.
I0110 18:56:38.854080 20959 net.cpp:226] fc6 needs backward computation.
I0110 18:56:38.854084 20959 net.cpp:226] pool5 needs backward computation.
I0110 18:56:38.854087 20959 net.cpp:226] relu5 needs backward computation.
I0110 18:56:38.854090 20959 net.cpp:226] conv5 needs backward computation.
I0110 18:56:38.854094 20959 net.cpp:226] relu4 needs backward computation.
I0110 18:56:38.854096 20959 net.cpp:226] conv4 needs backward computation.
I0110 18:56:38.854100 20959 net.cpp:226] relu3 needs backward computation.
I0110 18:56:38.854107 20959 net.cpp:226] conv3 needs backward computation.
I0110 18:56:38.854111 20959 net.cpp:226] pool2 needs backward computation.
I0110 18:56:38.854115 20959 net.cpp:226] norm2 needs backward computation.
I0110 18:56:38.854118 20959 net.cpp:226] relu2 needs backward computation.
I0110 18:56:38.854122 20959 net.cpp:226] conv2 needs backward computation.
I0110 18:56:38.854125 20959 net.cpp:226] pool1 needs backward computation.
I0110 18:56:38.854130 20959 net.cpp:226] norm1 needs backward computation.
I0110 18:56:38.854132 20959 net.cpp:226] relu1 needs backward computation.
I0110 18:56:38.854135 20959 net.cpp:226] conv1 needs backward computation.
I0110 18:56:38.854140 20959 net.cpp:228] data does not need backward computation.
I0110 18:56:38.854142 20959 net.cpp:228] data does not need backward computation.
I0110 18:56:38.854146 20959 net.cpp:270] This network produces output loss
I0110 18:56:38.854157 20959 net.cpp:283] Network initialization done.
I0110 18:56:38.854406 20959 solver.cpp:181] Creating test net (#0) specified by net file: temp_net.prototxt
I0110 18:56:38.854444 20959 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:56:38.854452 20959 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:56:38.854595 20959 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "test_loc.txt"
    batch_size: 8
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "label_list/test_label-3.txt"
    batch_size: 8
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:56:38.854681 20959 layer_factory.hpp:77] Creating layer data
I0110 18:56:38.854691 20959 net.cpp:100] Creating Layer data
I0110 18:56:38.854694 20959 net.cpp:408] data -> data
I0110 18:56:38.854701 20959 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: test_loc.txt
I0110 18:56:38.854722 20959 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0110 18:56:39.168053 20959 net.cpp:150] Setting up data
I0110 18:56:39.168094 20959 net.cpp:157] Top shape: 8 3 256 256 (1572864)
I0110 18:56:39.168103 20959 net.cpp:165] Memory required for data: 6291456
I0110 18:56:39.168113 20959 layer_factory.hpp:77] Creating layer data
I0110 18:56:39.168143 20959 net.cpp:100] Creating Layer data
I0110 18:56:39.168154 20959 net.cpp:408] data -> label
I0110 18:56:39.168169 20959 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/test_label-3.txt
I0110 18:56:39.168203 20959 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:56:39.169131 20959 net.cpp:150] Setting up data
I0110 18:56:39.169147 20959 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:56:39.169150 20959 net.cpp:165] Memory required for data: 6291488
I0110 18:56:39.169155 20959 layer_factory.hpp:77] Creating layer label_data_0_split
I0110 18:56:39.169164 20959 net.cpp:100] Creating Layer label_data_0_split
I0110 18:56:39.169168 20959 net.cpp:434] label_data_0_split <- label
I0110 18:56:39.169175 20959 net.cpp:408] label_data_0_split -> label_data_0_split_0
I0110 18:56:39.169183 20959 net.cpp:408] label_data_0_split -> label_data_0_split_1
I0110 18:56:39.169230 20959 net.cpp:150] Setting up label_data_0_split
I0110 18:56:39.169236 20959 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:56:39.169240 20959 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:56:39.169250 20959 net.cpp:165] Memory required for data: 6291552
I0110 18:56:39.169253 20959 layer_factory.hpp:77] Creating layer conv1
I0110 18:56:39.169265 20959 net.cpp:100] Creating Layer conv1
I0110 18:56:39.169268 20959 net.cpp:434] conv1 <- data
I0110 18:56:39.169273 20959 net.cpp:408] conv1 -> conv1
I0110 18:56:39.170611 20959 net.cpp:150] Setting up conv1
I0110 18:56:39.170626 20959 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:56:39.170630 20959 net.cpp:165] Memory required for data: 18100320
I0110 18:56:39.170640 20959 layer_factory.hpp:77] Creating layer relu1
I0110 18:56:39.170649 20959 net.cpp:100] Creating Layer relu1
I0110 18:56:39.170652 20959 net.cpp:434] relu1 <- conv1
I0110 18:56:39.170657 20959 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:56:39.171006 20959 net.cpp:150] Setting up relu1
I0110 18:56:39.171018 20959 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:56:39.171021 20959 net.cpp:165] Memory required for data: 29909088
I0110 18:56:39.171025 20959 layer_factory.hpp:77] Creating layer norm1
I0110 18:56:39.171033 20959 net.cpp:100] Creating Layer norm1
I0110 18:56:39.171036 20959 net.cpp:434] norm1 <- conv1
I0110 18:56:39.171041 20959 net.cpp:408] norm1 -> norm1
I0110 18:56:39.171205 20959 net.cpp:150] Setting up norm1
I0110 18:56:39.171213 20959 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:56:39.171216 20959 net.cpp:165] Memory required for data: 41717856
I0110 18:56:39.171219 20959 layer_factory.hpp:77] Creating layer pool1
I0110 18:56:39.171226 20959 net.cpp:100] Creating Layer pool1
I0110 18:56:39.171239 20959 net.cpp:434] pool1 <- norm1
I0110 18:56:39.171244 20959 net.cpp:408] pool1 -> pool1
I0110 18:56:39.171277 20959 net.cpp:150] Setting up pool1
I0110 18:56:39.171283 20959 net.cpp:157] Top shape: 8 96 31 31 (738048)
I0110 18:56:39.171286 20959 net.cpp:165] Memory required for data: 44670048
I0110 18:56:39.171289 20959 layer_factory.hpp:77] Creating layer conv2
I0110 18:56:39.171298 20959 net.cpp:100] Creating Layer conv2
I0110 18:56:39.171301 20959 net.cpp:434] conv2 <- pool1
I0110 18:56:39.171306 20959 net.cpp:408] conv2 -> conv2
I0110 18:56:39.176247 20959 net.cpp:150] Setting up conv2
I0110 18:56:39.176267 20959 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:56:39.176271 20959 net.cpp:165] Memory required for data: 52542560
I0110 18:56:39.176281 20959 layer_factory.hpp:77] Creating layer relu2
I0110 18:56:39.176290 20959 net.cpp:100] Creating Layer relu2
I0110 18:56:39.176293 20959 net.cpp:434] relu2 <- conv2
I0110 18:56:39.176298 20959 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:56:39.176628 20959 net.cpp:150] Setting up relu2
I0110 18:56:39.176640 20959 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:56:39.176643 20959 net.cpp:165] Memory required for data: 60415072
I0110 18:56:39.176647 20959 layer_factory.hpp:77] Creating layer norm2
I0110 18:56:39.176654 20959 net.cpp:100] Creating Layer norm2
I0110 18:56:39.176657 20959 net.cpp:434] norm2 <- conv2
I0110 18:56:39.176662 20959 net.cpp:408] norm2 -> norm2
I0110 18:56:39.176825 20959 net.cpp:150] Setting up norm2
I0110 18:56:39.176833 20959 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:56:39.176837 20959 net.cpp:165] Memory required for data: 68287584
I0110 18:56:39.176841 20959 layer_factory.hpp:77] Creating layer pool2
I0110 18:56:39.176846 20959 net.cpp:100] Creating Layer pool2
I0110 18:56:39.176851 20959 net.cpp:434] pool2 <- norm2
I0110 18:56:39.176854 20959 net.cpp:408] pool2 -> pool2
I0110 18:56:39.177186 20959 net.cpp:150] Setting up pool2
I0110 18:56:39.177196 20959 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:56:39.177201 20959 net.cpp:165] Memory required for data: 70130784
I0110 18:56:39.177203 20959 layer_factory.hpp:77] Creating layer conv3
I0110 18:56:39.177212 20959 net.cpp:100] Creating Layer conv3
I0110 18:56:39.177217 20959 net.cpp:434] conv3 <- pool2
I0110 18:56:39.177222 20959 net.cpp:408] conv3 -> conv3
I0110 18:56:39.187175 20959 net.cpp:150] Setting up conv3
I0110 18:56:39.187211 20959 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:56:39.187227 20959 net.cpp:165] Memory required for data: 72895584
I0110 18:56:39.187240 20959 layer_factory.hpp:77] Creating layer relu3
I0110 18:56:39.187250 20959 net.cpp:100] Creating Layer relu3
I0110 18:56:39.187255 20959 net.cpp:434] relu3 <- conv3
I0110 18:56:39.187263 20959 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:56:39.187607 20959 net.cpp:150] Setting up relu3
I0110 18:56:39.187619 20959 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:56:39.187623 20959 net.cpp:165] Memory required for data: 75660384
I0110 18:56:39.187628 20959 layer_factory.hpp:77] Creating layer conv4
I0110 18:56:39.187639 20959 net.cpp:100] Creating Layer conv4
I0110 18:56:39.187644 20959 net.cpp:434] conv4 <- conv3
I0110 18:56:39.187650 20959 net.cpp:408] conv4 -> conv4
I0110 18:56:39.196455 20959 net.cpp:150] Setting up conv4
I0110 18:56:39.196487 20959 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:56:39.196491 20959 net.cpp:165] Memory required for data: 78425184
I0110 18:56:39.196501 20959 layer_factory.hpp:77] Creating layer relu4
I0110 18:56:39.196508 20959 net.cpp:100] Creating Layer relu4
I0110 18:56:39.196513 20959 net.cpp:434] relu4 <- conv4
I0110 18:56:39.196519 20959 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:56:39.196665 20959 net.cpp:150] Setting up relu4
I0110 18:56:39.196673 20959 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:56:39.196677 20959 net.cpp:165] Memory required for data: 81189984
I0110 18:56:39.196681 20959 layer_factory.hpp:77] Creating layer conv5
I0110 18:56:39.196691 20959 net.cpp:100] Creating Layer conv5
I0110 18:56:39.196707 20959 net.cpp:434] conv5 <- conv4
I0110 18:56:39.196712 20959 net.cpp:408] conv5 -> conv5
I0110 18:56:39.203348 20959 net.cpp:150] Setting up conv5
I0110 18:56:39.203382 20959 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:56:39.203387 20959 net.cpp:165] Memory required for data: 83033184
I0110 18:56:39.203399 20959 layer_factory.hpp:77] Creating layer relu5
I0110 18:56:39.203410 20959 net.cpp:100] Creating Layer relu5
I0110 18:56:39.203415 20959 net.cpp:434] relu5 <- conv5
I0110 18:56:39.203421 20959 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:56:39.203569 20959 net.cpp:150] Setting up relu5
I0110 18:56:39.203578 20959 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:56:39.203583 20959 net.cpp:165] Memory required for data: 84876384
I0110 18:56:39.203586 20959 layer_factory.hpp:77] Creating layer pool5
I0110 18:56:39.203593 20959 net.cpp:100] Creating Layer pool5
I0110 18:56:39.203595 20959 net.cpp:434] pool5 <- conv5
I0110 18:56:39.203601 20959 net.cpp:408] pool5 -> pool5
I0110 18:56:39.203953 20959 net.cpp:150] Setting up pool5
I0110 18:56:39.203965 20959 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0110 18:56:39.203969 20959 net.cpp:165] Memory required for data: 85277792
I0110 18:56:39.203972 20959 layer_factory.hpp:77] Creating layer fc6
I0110 18:56:39.203979 20959 net.cpp:100] Creating Layer fc6
I0110 18:56:39.203984 20959 net.cpp:434] fc6 <- pool5
I0110 18:56:39.203989 20959 net.cpp:408] fc6 -> fc6
I0110 18:56:39.707401 20959 net.cpp:150] Setting up fc6
I0110 18:56:39.707449 20959 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:56:39.707459 20959 net.cpp:165] Memory required for data: 85408864
I0110 18:56:39.707475 20959 layer_factory.hpp:77] Creating layer relu6
I0110 18:56:39.707489 20959 net.cpp:100] Creating Layer relu6
I0110 18:56:39.707497 20959 net.cpp:434] relu6 <- fc6
I0110 18:56:39.707505 20959 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:56:39.707763 20959 net.cpp:150] Setting up relu6
I0110 18:56:39.707775 20959 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:56:39.707779 20959 net.cpp:165] Memory required for data: 85539936
I0110 18:56:39.707783 20959 layer_factory.hpp:77] Creating layer drop6
I0110 18:56:39.707792 20959 net.cpp:100] Creating Layer drop6
I0110 18:56:39.707797 20959 net.cpp:434] drop6 <- fc6
I0110 18:56:39.707801 20959 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:56:39.707835 20959 net.cpp:150] Setting up drop6
I0110 18:56:39.707842 20959 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:56:39.707854 20959 net.cpp:165] Memory required for data: 85671008
I0110 18:56:39.707857 20959 layer_factory.hpp:77] Creating layer fc7
I0110 18:56:39.707865 20959 net.cpp:100] Creating Layer fc7
I0110 18:56:39.707870 20959 net.cpp:434] fc7 <- fc6
I0110 18:56:39.707875 20959 net.cpp:408] fc7 -> fc7
I0110 18:56:39.870704 20959 net.cpp:150] Setting up fc7
I0110 18:56:39.870748 20959 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:56:39.870755 20959 net.cpp:165] Memory required for data: 85802080
I0110 18:56:39.870767 20959 layer_factory.hpp:77] Creating layer relu7
I0110 18:56:39.870777 20959 net.cpp:100] Creating Layer relu7
I0110 18:56:39.870782 20959 net.cpp:434] relu7 <- fc7
I0110 18:56:39.870790 20959 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:56:39.871273 20959 net.cpp:150] Setting up relu7
I0110 18:56:39.871287 20959 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:56:39.871291 20959 net.cpp:165] Memory required for data: 85933152
I0110 18:56:39.871295 20959 layer_factory.hpp:77] Creating layer drop7
I0110 18:56:39.871304 20959 net.cpp:100] Creating Layer drop7
I0110 18:56:39.871309 20959 net.cpp:434] drop7 <- fc7
I0110 18:56:39.871315 20959 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:56:39.871351 20959 net.cpp:150] Setting up drop7
I0110 18:56:39.871358 20959 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:56:39.871361 20959 net.cpp:165] Memory required for data: 86064224
I0110 18:56:39.871364 20959 layer_factory.hpp:77] Creating layer fc8
I0110 18:56:39.871372 20959 net.cpp:100] Creating Layer fc8
I0110 18:56:39.871376 20959 net.cpp:434] fc8 <- fc7
I0110 18:56:39.871394 20959 net.cpp:408] fc8 -> fc8
I0110 18:56:39.871551 20959 net.cpp:150] Setting up fc8
I0110 18:56:39.871557 20959 net.cpp:157] Top shape: 8 1 (8)
I0110 18:56:39.871561 20959 net.cpp:165] Memory required for data: 86064256
I0110 18:56:39.871567 20959 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0110 18:56:39.871572 20959 net.cpp:100] Creating Layer fc8_fc8_0_split
I0110 18:56:39.871577 20959 net.cpp:434] fc8_fc8_0_split <- fc8
I0110 18:56:39.871582 20959 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0110 18:56:39.871587 20959 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0110 18:56:39.871623 20959 net.cpp:150] Setting up fc8_fc8_0_split
I0110 18:56:39.871628 20959 net.cpp:157] Top shape: 8 1 (8)
I0110 18:56:39.871632 20959 net.cpp:157] Top shape: 8 1 (8)
I0110 18:56:39.871635 20959 net.cpp:165] Memory required for data: 86064320
I0110 18:56:39.871639 20959 layer_factory.hpp:77] Creating layer accuracy
I0110 18:56:39.871644 20959 net.cpp:100] Creating Layer accuracy
I0110 18:56:39.871649 20959 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0110 18:56:39.871652 20959 net.cpp:434] accuracy <- label_data_0_split_0
I0110 18:56:39.871657 20959 net.cpp:408] accuracy -> accuracy
I0110 18:56:39.871671 20959 net.cpp:150] Setting up accuracy
I0110 18:56:39.871677 20959 net.cpp:157] Top shape: (1)
I0110 18:56:39.871680 20959 net.cpp:165] Memory required for data: 86064324
I0110 18:56:39.871683 20959 layer_factory.hpp:77] Creating layer loss
I0110 18:56:39.871688 20959 net.cpp:100] Creating Layer loss
I0110 18:56:39.871691 20959 net.cpp:434] loss <- fc8_fc8_0_split_1
I0110 18:56:39.871695 20959 net.cpp:434] loss <- label_data_0_split_1
I0110 18:56:39.871701 20959 net.cpp:408] loss -> loss
I0110 18:56:39.871707 20959 layer_factory.hpp:77] Creating layer loss
I0110 18:56:39.871942 20959 net.cpp:150] Setting up loss
I0110 18:56:39.871951 20959 net.cpp:157] Top shape: (1)
I0110 18:56:39.871955 20959 net.cpp:160]     with loss weight 1
I0110 18:56:39.871965 20959 net.cpp:165] Memory required for data: 86064328
I0110 18:56:39.871968 20959 net.cpp:226] loss needs backward computation.
I0110 18:56:39.871973 20959 net.cpp:228] accuracy does not need backward computation.
I0110 18:56:39.871978 20959 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0110 18:56:39.871980 20959 net.cpp:226] fc8 needs backward computation.
I0110 18:56:39.871984 20959 net.cpp:226] drop7 needs backward computation.
I0110 18:56:39.871987 20959 net.cpp:226] relu7 needs backward computation.
I0110 18:56:39.871994 20959 net.cpp:226] fc7 needs backward computation.
I0110 18:56:39.871999 20959 net.cpp:226] drop6 needs backward computation.
I0110 18:56:39.872001 20959 net.cpp:226] relu6 needs backward computation.
I0110 18:56:39.872004 20959 net.cpp:226] fc6 needs backward computation.
I0110 18:56:39.872007 20959 net.cpp:226] pool5 needs backward computation.
I0110 18:56:39.872011 20959 net.cpp:226] relu5 needs backward computation.
I0110 18:56:39.872014 20959 net.cpp:226] conv5 needs backward computation.
I0110 18:56:39.872018 20959 net.cpp:226] relu4 needs backward computation.
I0110 18:56:39.872021 20959 net.cpp:226] conv4 needs backward computation.
I0110 18:56:39.872025 20959 net.cpp:226] relu3 needs backward computation.
I0110 18:56:39.872028 20959 net.cpp:226] conv3 needs backward computation.
I0110 18:56:39.872031 20959 net.cpp:226] pool2 needs backward computation.
I0110 18:56:39.872035 20959 net.cpp:226] norm2 needs backward computation.
I0110 18:56:39.872038 20959 net.cpp:226] relu2 needs backward computation.
I0110 18:56:39.872041 20959 net.cpp:226] conv2 needs backward computation.
I0110 18:56:39.872045 20959 net.cpp:226] pool1 needs backward computation.
I0110 18:56:39.872048 20959 net.cpp:226] norm1 needs backward computation.
I0110 18:56:39.872051 20959 net.cpp:226] relu1 needs backward computation.
I0110 18:56:39.872054 20959 net.cpp:226] conv1 needs backward computation.
I0110 18:56:39.872058 20959 net.cpp:228] label_data_0_split does not need backward computation.
I0110 18:56:39.872062 20959 net.cpp:228] data does not need backward computation.
I0110 18:56:39.872072 20959 net.cpp:228] data does not need backward computation.
I0110 18:56:39.872076 20959 net.cpp:270] This network produces output accuracy
I0110 18:56:39.872079 20959 net.cpp:270] This network produces output loss
I0110 18:56:39.872094 20959 net.cpp:283] Network initialization done.
I0110 18:56:39.872170 20959 solver.cpp:60] Solver scaffolding done.
I0110 18:56:39.872691 20959 caffe.cpp:251] Starting Optimization
I0110 18:56:39.872697 20959 solver.cpp:279] Solving AlexNet
I0110 18:56:39.872700 20959 solver.cpp:280] Learning Rate Policy: step
I0110 18:56:39.874927 20959 solver.cpp:337] Iteration 0, Testing net (#0)
I0110 18:56:39.941867 20959 solver.cpp:386] Test interrupted.
I0110 18:56:39.941916 20959 solver.cpp:301] Optimization stopped early.
I0110 18:56:39.941932 20959 caffe.cpp:254] Optimization Done.
I0110 18:56:40.483212 20973 caffe.cpp:217] Using GPUs 0
I0110 18:56:40.483739 20973 caffe.cpp:222] GPU 0: GeForce 840M
I0110 18:59:09.088029 21167 caffe.cpp:217] Using GPUs 0
I0110 18:59:09.088589 21167 caffe.cpp:222] GPU 0: GeForce 840M
I0110 18:59:09.298270 21167 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2383
test_interval: 4000
base_lr: 0.01
display: 200
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 12000
snapshot: 4000
snapshot_prefix: "models/1/caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "temp_net.prototxt"
train_state {
  level: 0
  stage: ""
}
I0110 18:59:09.298408 21167 solver.cpp:91] Creating training net from net file: temp_net.prototxt
I0110 18:59:09.298696 21167 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:59:09.298707 21167 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0110 18:59:09.298717 21167 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0110 18:59:09.298854 21167 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "train_loc.txt"
    batch_size: 16
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "label_list/train_label-1.txt"
    batch_size: 16
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:59:09.298940 21167 layer_factory.hpp:77] Creating layer data
I0110 18:59:09.298952 21167 net.cpp:100] Creating Layer data
I0110 18:59:09.298959 21167 net.cpp:408] data -> data
I0110 18:59:09.298980 21167 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: train_loc.txt
I0110 18:59:09.299020 21167 hdf5_data_layer.cpp:93] Number of HDF5 files: 38
I0110 18:59:09.299854 21167 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0110 18:59:09.626086 21167 net.cpp:150] Setting up data
I0110 18:59:09.626139 21167 net.cpp:157] Top shape: 16 3 256 256 (3145728)
I0110 18:59:09.626144 21167 net.cpp:165] Memory required for data: 12582912
I0110 18:59:09.626152 21167 layer_factory.hpp:77] Creating layer data
I0110 18:59:09.626165 21167 net.cpp:100] Creating Layer data
I0110 18:59:09.626171 21167 net.cpp:408] data -> label
I0110 18:59:09.626183 21167 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/train_label-1.txt
I0110 18:59:09.626217 21167 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:59:09.626492 21167 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0110 18:59:09.627403 21167 net.cpp:150] Setting up data
I0110 18:59:09.627427 21167 net.cpp:157] Top shape: 16 1 1 1 (16)
I0110 18:59:09.627432 21167 net.cpp:165] Memory required for data: 12582976
I0110 18:59:09.627437 21167 layer_factory.hpp:77] Creating layer conv1
I0110 18:59:09.627455 21167 net.cpp:100] Creating Layer conv1
I0110 18:59:09.627461 21167 net.cpp:434] conv1 <- data
I0110 18:59:09.627472 21167 net.cpp:408] conv1 -> conv1
I0110 18:59:09.822230 21167 net.cpp:150] Setting up conv1
I0110 18:59:09.822268 21167 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:59:09.822273 21167 net.cpp:165] Memory required for data: 36200512
I0110 18:59:09.822294 21167 layer_factory.hpp:77] Creating layer relu1
I0110 18:59:09.822306 21167 net.cpp:100] Creating Layer relu1
I0110 18:59:09.822311 21167 net.cpp:434] relu1 <- conv1
I0110 18:59:09.822317 21167 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:59:09.822484 21167 net.cpp:150] Setting up relu1
I0110 18:59:09.822494 21167 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:59:09.822499 21167 net.cpp:165] Memory required for data: 59818048
I0110 18:59:09.822502 21167 layer_factory.hpp:77] Creating layer norm1
I0110 18:59:09.822525 21167 net.cpp:100] Creating Layer norm1
I0110 18:59:09.822528 21167 net.cpp:434] norm1 <- conv1
I0110 18:59:09.822535 21167 net.cpp:408] norm1 -> norm1
I0110 18:59:09.822901 21167 net.cpp:150] Setting up norm1
I0110 18:59:09.822913 21167 net.cpp:157] Top shape: 16 96 62 62 (5904384)
I0110 18:59:09.822917 21167 net.cpp:165] Memory required for data: 83435584
I0110 18:59:09.822921 21167 layer_factory.hpp:77] Creating layer pool1
I0110 18:59:09.822927 21167 net.cpp:100] Creating Layer pool1
I0110 18:59:09.822932 21167 net.cpp:434] pool1 <- norm1
I0110 18:59:09.822939 21167 net.cpp:408] pool1 -> pool1
I0110 18:59:09.822979 21167 net.cpp:150] Setting up pool1
I0110 18:59:09.822988 21167 net.cpp:157] Top shape: 16 96 31 31 (1476096)
I0110 18:59:09.822991 21167 net.cpp:165] Memory required for data: 89339968
I0110 18:59:09.822995 21167 layer_factory.hpp:77] Creating layer conv2
I0110 18:59:09.823005 21167 net.cpp:100] Creating Layer conv2
I0110 18:59:09.823010 21167 net.cpp:434] conv2 <- pool1
I0110 18:59:09.823015 21167 net.cpp:408] conv2 -> conv2
I0110 18:59:09.828284 21167 net.cpp:150] Setting up conv2
I0110 18:59:09.828330 21167 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:59:09.828335 21167 net.cpp:165] Memory required for data: 105084992
I0110 18:59:09.828347 21167 layer_factory.hpp:77] Creating layer relu2
I0110 18:59:09.828366 21167 net.cpp:100] Creating Layer relu2
I0110 18:59:09.828377 21167 net.cpp:434] relu2 <- conv2
I0110 18:59:09.828384 21167 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:59:09.828722 21167 net.cpp:150] Setting up relu2
I0110 18:59:09.828734 21167 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:59:09.828737 21167 net.cpp:165] Memory required for data: 120830016
I0110 18:59:09.828742 21167 layer_factory.hpp:77] Creating layer norm2
I0110 18:59:09.828750 21167 net.cpp:100] Creating Layer norm2
I0110 18:59:09.828755 21167 net.cpp:434] norm2 <- conv2
I0110 18:59:09.828763 21167 net.cpp:408] norm2 -> norm2
I0110 18:59:09.828927 21167 net.cpp:150] Setting up norm2
I0110 18:59:09.828935 21167 net.cpp:157] Top shape: 16 256 31 31 (3936256)
I0110 18:59:09.828939 21167 net.cpp:165] Memory required for data: 136575040
I0110 18:59:09.828943 21167 layer_factory.hpp:77] Creating layer pool2
I0110 18:59:09.828948 21167 net.cpp:100] Creating Layer pool2
I0110 18:59:09.828953 21167 net.cpp:434] pool2 <- norm2
I0110 18:59:09.828958 21167 net.cpp:408] pool2 -> pool2
I0110 18:59:09.829295 21167 net.cpp:150] Setting up pool2
I0110 18:59:09.829306 21167 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:59:09.829310 21167 net.cpp:165] Memory required for data: 140261440
I0110 18:59:09.829313 21167 layer_factory.hpp:77] Creating layer conv3
I0110 18:59:09.829324 21167 net.cpp:100] Creating Layer conv3
I0110 18:59:09.829329 21167 net.cpp:434] conv3 <- pool2
I0110 18:59:09.829335 21167 net.cpp:408] conv3 -> conv3
I0110 18:59:09.839339 21167 net.cpp:150] Setting up conv3
I0110 18:59:09.839372 21167 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:59:09.839376 21167 net.cpp:165] Memory required for data: 145791040
I0110 18:59:09.839388 21167 layer_factory.hpp:77] Creating layer relu3
I0110 18:59:09.839397 21167 net.cpp:100] Creating Layer relu3
I0110 18:59:09.839402 21167 net.cpp:434] relu3 <- conv3
I0110 18:59:09.839409 21167 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:59:09.839560 21167 net.cpp:150] Setting up relu3
I0110 18:59:09.839570 21167 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:59:09.839572 21167 net.cpp:165] Memory required for data: 151320640
I0110 18:59:09.839576 21167 layer_factory.hpp:77] Creating layer conv4
I0110 18:59:09.839586 21167 net.cpp:100] Creating Layer conv4
I0110 18:59:09.839591 21167 net.cpp:434] conv4 <- conv3
I0110 18:59:09.839597 21167 net.cpp:408] conv4 -> conv4
I0110 18:59:09.848217 21167 net.cpp:150] Setting up conv4
I0110 18:59:09.848253 21167 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:59:09.848256 21167 net.cpp:165] Memory required for data: 156850240
I0110 18:59:09.848265 21167 layer_factory.hpp:77] Creating layer relu4
I0110 18:59:09.848285 21167 net.cpp:100] Creating Layer relu4
I0110 18:59:09.848289 21167 net.cpp:434] relu4 <- conv4
I0110 18:59:09.848297 21167 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:59:09.848446 21167 net.cpp:150] Setting up relu4
I0110 18:59:09.848455 21167 net.cpp:157] Top shape: 16 384 15 15 (1382400)
I0110 18:59:09.848459 21167 net.cpp:165] Memory required for data: 162379840
I0110 18:59:09.848462 21167 layer_factory.hpp:77] Creating layer conv5
I0110 18:59:09.848474 21167 net.cpp:100] Creating Layer conv5
I0110 18:59:09.848477 21167 net.cpp:434] conv5 <- conv4
I0110 18:59:09.848484 21167 net.cpp:408] conv5 -> conv5
I0110 18:59:09.855062 21167 net.cpp:150] Setting up conv5
I0110 18:59:09.855092 21167 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:59:09.855094 21167 net.cpp:165] Memory required for data: 166066240
I0110 18:59:09.855106 21167 layer_factory.hpp:77] Creating layer relu5
I0110 18:59:09.855115 21167 net.cpp:100] Creating Layer relu5
I0110 18:59:09.855119 21167 net.cpp:434] relu5 <- conv5
I0110 18:59:09.855128 21167 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:59:09.855278 21167 net.cpp:150] Setting up relu5
I0110 18:59:09.855288 21167 net.cpp:157] Top shape: 16 256 15 15 (921600)
I0110 18:59:09.855291 21167 net.cpp:165] Memory required for data: 169752640
I0110 18:59:09.855294 21167 layer_factory.hpp:77] Creating layer pool5
I0110 18:59:09.855312 21167 net.cpp:100] Creating Layer pool5
I0110 18:59:09.855317 21167 net.cpp:434] pool5 <- conv5
I0110 18:59:09.855322 21167 net.cpp:408] pool5 -> pool5
I0110 18:59:09.855659 21167 net.cpp:150] Setting up pool5
I0110 18:59:09.855677 21167 net.cpp:157] Top shape: 16 256 7 7 (200704)
I0110 18:59:09.855681 21167 net.cpp:165] Memory required for data: 170555456
I0110 18:59:09.855685 21167 layer_factory.hpp:77] Creating layer fc6
I0110 18:59:09.855695 21167 net.cpp:100] Creating Layer fc6
I0110 18:59:09.855698 21167 net.cpp:434] fc6 <- pool5
I0110 18:59:09.855705 21167 net.cpp:408] fc6 -> fc6
I0110 18:59:10.344326 21167 net.cpp:150] Setting up fc6
I0110 18:59:10.344377 21167 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:59:10.344382 21167 net.cpp:165] Memory required for data: 170817600
I0110 18:59:10.344393 21167 layer_factory.hpp:77] Creating layer relu6
I0110 18:59:10.344401 21167 net.cpp:100] Creating Layer relu6
I0110 18:59:10.344408 21167 net.cpp:434] relu6 <- fc6
I0110 18:59:10.344413 21167 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:59:10.344861 21167 net.cpp:150] Setting up relu6
I0110 18:59:10.344871 21167 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:59:10.344874 21167 net.cpp:165] Memory required for data: 171079744
I0110 18:59:10.344877 21167 layer_factory.hpp:77] Creating layer drop6
I0110 18:59:10.344884 21167 net.cpp:100] Creating Layer drop6
I0110 18:59:10.344887 21167 net.cpp:434] drop6 <- fc6
I0110 18:59:10.344892 21167 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:59:10.344921 21167 net.cpp:150] Setting up drop6
I0110 18:59:10.344928 21167 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:59:10.344931 21167 net.cpp:165] Memory required for data: 171341888
I0110 18:59:10.344934 21167 layer_factory.hpp:77] Creating layer fc7
I0110 18:59:10.344943 21167 net.cpp:100] Creating Layer fc7
I0110 18:59:10.344946 21167 net.cpp:434] fc7 <- fc6
I0110 18:59:10.344951 21167 net.cpp:408] fc7 -> fc7
I0110 18:59:10.504420 21167 net.cpp:150] Setting up fc7
I0110 18:59:10.504467 21167 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:59:10.504472 21167 net.cpp:165] Memory required for data: 171604032
I0110 18:59:10.504482 21167 layer_factory.hpp:77] Creating layer relu7
I0110 18:59:10.504493 21167 net.cpp:100] Creating Layer relu7
I0110 18:59:10.504508 21167 net.cpp:434] relu7 <- fc7
I0110 18:59:10.504513 21167 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:59:10.504714 21167 net.cpp:150] Setting up relu7
I0110 18:59:10.504724 21167 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:59:10.504726 21167 net.cpp:165] Memory required for data: 171866176
I0110 18:59:10.504729 21167 layer_factory.hpp:77] Creating layer drop7
I0110 18:59:10.504753 21167 net.cpp:100] Creating Layer drop7
I0110 18:59:10.504758 21167 net.cpp:434] drop7 <- fc7
I0110 18:59:10.504763 21167 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:59:10.504788 21167 net.cpp:150] Setting up drop7
I0110 18:59:10.504794 21167 net.cpp:157] Top shape: 16 4096 (65536)
I0110 18:59:10.504797 21167 net.cpp:165] Memory required for data: 172128320
I0110 18:59:10.504801 21167 layer_factory.hpp:77] Creating layer fc8
I0110 18:59:10.504809 21167 net.cpp:100] Creating Layer fc8
I0110 18:59:10.504812 21167 net.cpp:434] fc8 <- fc7
I0110 18:59:10.504818 21167 net.cpp:408] fc8 -> fc8
I0110 18:59:10.504940 21167 net.cpp:150] Setting up fc8
I0110 18:59:10.504947 21167 net.cpp:157] Top shape: 16 1 (16)
I0110 18:59:10.504951 21167 net.cpp:165] Memory required for data: 172128384
I0110 18:59:10.504956 21167 layer_factory.hpp:77] Creating layer loss
I0110 18:59:10.504961 21167 net.cpp:100] Creating Layer loss
I0110 18:59:10.504966 21167 net.cpp:434] loss <- fc8
I0110 18:59:10.504969 21167 net.cpp:434] loss <- label
I0110 18:59:10.504976 21167 net.cpp:408] loss -> loss
I0110 18:59:10.504987 21167 layer_factory.hpp:77] Creating layer loss
I0110 18:59:10.505448 21167 net.cpp:150] Setting up loss
I0110 18:59:10.505458 21167 net.cpp:157] Top shape: (1)
I0110 18:59:10.505462 21167 net.cpp:160]     with loss weight 1
I0110 18:59:10.505483 21167 net.cpp:165] Memory required for data: 172128388
I0110 18:59:10.505491 21167 net.cpp:226] loss needs backward computation.
I0110 18:59:10.505498 21167 net.cpp:226] fc8 needs backward computation.
I0110 18:59:10.505501 21167 net.cpp:226] drop7 needs backward computation.
I0110 18:59:10.505506 21167 net.cpp:226] relu7 needs backward computation.
I0110 18:59:10.505507 21167 net.cpp:226] fc7 needs backward computation.
I0110 18:59:10.505511 21167 net.cpp:226] drop6 needs backward computation.
I0110 18:59:10.505514 21167 net.cpp:226] relu6 needs backward computation.
I0110 18:59:10.505517 21167 net.cpp:226] fc6 needs backward computation.
I0110 18:59:10.505522 21167 net.cpp:226] pool5 needs backward computation.
I0110 18:59:10.505524 21167 net.cpp:226] relu5 needs backward computation.
I0110 18:59:10.505528 21167 net.cpp:226] conv5 needs backward computation.
I0110 18:59:10.505532 21167 net.cpp:226] relu4 needs backward computation.
I0110 18:59:10.505534 21167 net.cpp:226] conv4 needs backward computation.
I0110 18:59:10.505538 21167 net.cpp:226] relu3 needs backward computation.
I0110 18:59:10.505542 21167 net.cpp:226] conv3 needs backward computation.
I0110 18:59:10.505544 21167 net.cpp:226] pool2 needs backward computation.
I0110 18:59:10.505548 21167 net.cpp:226] norm2 needs backward computation.
I0110 18:59:10.505551 21167 net.cpp:226] relu2 needs backward computation.
I0110 18:59:10.505555 21167 net.cpp:226] conv2 needs backward computation.
I0110 18:59:10.505558 21167 net.cpp:226] pool1 needs backward computation.
I0110 18:59:10.505563 21167 net.cpp:226] norm1 needs backward computation.
I0110 18:59:10.505565 21167 net.cpp:226] relu1 needs backward computation.
I0110 18:59:10.505568 21167 net.cpp:226] conv1 needs backward computation.
I0110 18:59:10.505573 21167 net.cpp:228] data does not need backward computation.
I0110 18:59:10.505578 21167 net.cpp:228] data does not need backward computation.
I0110 18:59:10.505580 21167 net.cpp:270] This network produces output loss
I0110 18:59:10.505594 21167 net.cpp:283] Network initialization done.
I0110 18:59:10.505833 21167 solver.cpp:181] Creating test net (#0) specified by net file: temp_net.prototxt
I0110 18:59:10.505862 21167 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:59:10.505867 21167 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0110 18:59:10.506005 21167 net.cpp:58] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "test_loc.txt"
    batch_size: 8
  }
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "label_list/test_label-1.txt"
    batch_size: 8
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0110 18:59:10.506095 21167 layer_factory.hpp:77] Creating layer data
I0110 18:59:10.506105 21167 net.cpp:100] Creating Layer data
I0110 18:59:10.506109 21167 net.cpp:408] data -> data
I0110 18:59:10.506116 21167 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: test_loc.txt
I0110 18:59:10.506139 21167 hdf5_data_layer.cpp:93] Number of HDF5 files: 10
I0110 18:59:10.820231 21167 net.cpp:150] Setting up data
I0110 18:59:10.820281 21167 net.cpp:157] Top shape: 8 3 256 256 (1572864)
I0110 18:59:10.820289 21167 net.cpp:165] Memory required for data: 6291456
I0110 18:59:10.820297 21167 layer_factory.hpp:77] Creating layer data
I0110 18:59:10.820320 21167 net.cpp:100] Creating Layer data
I0110 18:59:10.820330 21167 net.cpp:408] data -> label
I0110 18:59:10.820343 21167 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: label_list/test_label-1.txt
I0110 18:59:10.820379 21167 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0110 18:59:10.821434 21167 net.cpp:150] Setting up data
I0110 18:59:10.821451 21167 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:59:10.821456 21167 net.cpp:165] Memory required for data: 6291488
I0110 18:59:10.821461 21167 layer_factory.hpp:77] Creating layer label_data_0_split
I0110 18:59:10.821470 21167 net.cpp:100] Creating Layer label_data_0_split
I0110 18:59:10.821475 21167 net.cpp:434] label_data_0_split <- label
I0110 18:59:10.821482 21167 net.cpp:408] label_data_0_split -> label_data_0_split_0
I0110 18:59:10.821491 21167 net.cpp:408] label_data_0_split -> label_data_0_split_1
I0110 18:59:10.821539 21167 net.cpp:150] Setting up label_data_0_split
I0110 18:59:10.821545 21167 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:59:10.821550 21167 net.cpp:157] Top shape: 8 1 1 1 (8)
I0110 18:59:10.821553 21167 net.cpp:165] Memory required for data: 6291552
I0110 18:59:10.821557 21167 layer_factory.hpp:77] Creating layer conv1
I0110 18:59:10.821568 21167 net.cpp:100] Creating Layer conv1
I0110 18:59:10.821573 21167 net.cpp:434] conv1 <- data
I0110 18:59:10.821578 21167 net.cpp:408] conv1 -> conv1
I0110 18:59:10.822892 21167 net.cpp:150] Setting up conv1
I0110 18:59:10.822906 21167 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:59:10.822911 21167 net.cpp:165] Memory required for data: 18100320
I0110 18:59:10.822921 21167 layer_factory.hpp:77] Creating layer relu1
I0110 18:59:10.822928 21167 net.cpp:100] Creating Layer relu1
I0110 18:59:10.822932 21167 net.cpp:434] relu1 <- conv1
I0110 18:59:10.822937 21167 net.cpp:395] relu1 -> conv1 (in-place)
I0110 18:59:10.823289 21167 net.cpp:150] Setting up relu1
I0110 18:59:10.823302 21167 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:59:10.823304 21167 net.cpp:165] Memory required for data: 29909088
I0110 18:59:10.823308 21167 layer_factory.hpp:77] Creating layer norm1
I0110 18:59:10.823315 21167 net.cpp:100] Creating Layer norm1
I0110 18:59:10.823319 21167 net.cpp:434] norm1 <- conv1
I0110 18:59:10.823324 21167 net.cpp:408] norm1 -> norm1
I0110 18:59:10.823487 21167 net.cpp:150] Setting up norm1
I0110 18:59:10.823496 21167 net.cpp:157] Top shape: 8 96 62 62 (2952192)
I0110 18:59:10.823499 21167 net.cpp:165] Memory required for data: 41717856
I0110 18:59:10.823503 21167 layer_factory.hpp:77] Creating layer pool1
I0110 18:59:10.823509 21167 net.cpp:100] Creating Layer pool1
I0110 18:59:10.823524 21167 net.cpp:434] pool1 <- norm1
I0110 18:59:10.823529 21167 net.cpp:408] pool1 -> pool1
I0110 18:59:10.823562 21167 net.cpp:150] Setting up pool1
I0110 18:59:10.823570 21167 net.cpp:157] Top shape: 8 96 31 31 (738048)
I0110 18:59:10.823572 21167 net.cpp:165] Memory required for data: 44670048
I0110 18:59:10.823575 21167 layer_factory.hpp:77] Creating layer conv2
I0110 18:59:10.823585 21167 net.cpp:100] Creating Layer conv2
I0110 18:59:10.823587 21167 net.cpp:434] conv2 <- pool1
I0110 18:59:10.823592 21167 net.cpp:408] conv2 -> conv2
I0110 18:59:10.828471 21167 net.cpp:150] Setting up conv2
I0110 18:59:10.828493 21167 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:59:10.828497 21167 net.cpp:165] Memory required for data: 52542560
I0110 18:59:10.828507 21167 layer_factory.hpp:77] Creating layer relu2
I0110 18:59:10.828516 21167 net.cpp:100] Creating Layer relu2
I0110 18:59:10.828521 21167 net.cpp:434] relu2 <- conv2
I0110 18:59:10.828526 21167 net.cpp:395] relu2 -> conv2 (in-place)
I0110 18:59:10.828845 21167 net.cpp:150] Setting up relu2
I0110 18:59:10.828855 21167 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:59:10.828858 21167 net.cpp:165] Memory required for data: 60415072
I0110 18:59:10.828862 21167 layer_factory.hpp:77] Creating layer norm2
I0110 18:59:10.828868 21167 net.cpp:100] Creating Layer norm2
I0110 18:59:10.828872 21167 net.cpp:434] norm2 <- conv2
I0110 18:59:10.828883 21167 net.cpp:408] norm2 -> norm2
I0110 18:59:10.829044 21167 net.cpp:150] Setting up norm2
I0110 18:59:10.829052 21167 net.cpp:157] Top shape: 8 256 31 31 (1968128)
I0110 18:59:10.829056 21167 net.cpp:165] Memory required for data: 68287584
I0110 18:59:10.829059 21167 layer_factory.hpp:77] Creating layer pool2
I0110 18:59:10.829066 21167 net.cpp:100] Creating Layer pool2
I0110 18:59:10.829068 21167 net.cpp:434] pool2 <- norm2
I0110 18:59:10.829073 21167 net.cpp:408] pool2 -> pool2
I0110 18:59:10.829401 21167 net.cpp:150] Setting up pool2
I0110 18:59:10.829412 21167 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:59:10.829416 21167 net.cpp:165] Memory required for data: 70130784
I0110 18:59:10.829419 21167 layer_factory.hpp:77] Creating layer conv3
I0110 18:59:10.829428 21167 net.cpp:100] Creating Layer conv3
I0110 18:59:10.829432 21167 net.cpp:434] conv3 <- pool2
I0110 18:59:10.829438 21167 net.cpp:408] conv3 -> conv3
I0110 18:59:10.839267 21167 net.cpp:150] Setting up conv3
I0110 18:59:10.839300 21167 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:59:10.839304 21167 net.cpp:165] Memory required for data: 72895584
I0110 18:59:10.839316 21167 layer_factory.hpp:77] Creating layer relu3
I0110 18:59:10.839324 21167 net.cpp:100] Creating Layer relu3
I0110 18:59:10.839329 21167 net.cpp:434] relu3 <- conv3
I0110 18:59:10.839336 21167 net.cpp:395] relu3 -> conv3 (in-place)
I0110 18:59:10.839645 21167 net.cpp:150] Setting up relu3
I0110 18:59:10.839656 21167 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:59:10.839660 21167 net.cpp:165] Memory required for data: 75660384
I0110 18:59:10.839681 21167 layer_factory.hpp:77] Creating layer conv4
I0110 18:59:10.839691 21167 net.cpp:100] Creating Layer conv4
I0110 18:59:10.839695 21167 net.cpp:434] conv4 <- conv3
I0110 18:59:10.839702 21167 net.cpp:408] conv4 -> conv4
I0110 18:59:10.848501 21167 net.cpp:150] Setting up conv4
I0110 18:59:10.848536 21167 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:59:10.848541 21167 net.cpp:165] Memory required for data: 78425184
I0110 18:59:10.848549 21167 layer_factory.hpp:77] Creating layer relu4
I0110 18:59:10.848558 21167 net.cpp:100] Creating Layer relu4
I0110 18:59:10.848562 21167 net.cpp:434] relu4 <- conv4
I0110 18:59:10.848568 21167 net.cpp:395] relu4 -> conv4 (in-place)
I0110 18:59:10.848728 21167 net.cpp:150] Setting up relu4
I0110 18:59:10.848737 21167 net.cpp:157] Top shape: 8 384 15 15 (691200)
I0110 18:59:10.848740 21167 net.cpp:165] Memory required for data: 81189984
I0110 18:59:10.848744 21167 layer_factory.hpp:77] Creating layer conv5
I0110 18:59:10.848754 21167 net.cpp:100] Creating Layer conv5
I0110 18:59:10.848770 21167 net.cpp:434] conv5 <- conv4
I0110 18:59:10.848778 21167 net.cpp:408] conv5 -> conv5
I0110 18:59:10.855232 21167 net.cpp:150] Setting up conv5
I0110 18:59:10.855264 21167 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:59:10.855269 21167 net.cpp:165] Memory required for data: 83033184
I0110 18:59:10.855281 21167 layer_factory.hpp:77] Creating layer relu5
I0110 18:59:10.855293 21167 net.cpp:100] Creating Layer relu5
I0110 18:59:10.855298 21167 net.cpp:434] relu5 <- conv5
I0110 18:59:10.855304 21167 net.cpp:395] relu5 -> conv5 (in-place)
I0110 18:59:10.855458 21167 net.cpp:150] Setting up relu5
I0110 18:59:10.855468 21167 net.cpp:157] Top shape: 8 256 15 15 (460800)
I0110 18:59:10.855470 21167 net.cpp:165] Memory required for data: 84876384
I0110 18:59:10.855474 21167 layer_factory.hpp:77] Creating layer pool5
I0110 18:59:10.855482 21167 net.cpp:100] Creating Layer pool5
I0110 18:59:10.855486 21167 net.cpp:434] pool5 <- conv5
I0110 18:59:10.855491 21167 net.cpp:408] pool5 -> pool5
I0110 18:59:10.855849 21167 net.cpp:150] Setting up pool5
I0110 18:59:10.855861 21167 net.cpp:157] Top shape: 8 256 7 7 (100352)
I0110 18:59:10.855865 21167 net.cpp:165] Memory required for data: 85277792
I0110 18:59:10.855868 21167 layer_factory.hpp:77] Creating layer fc6
I0110 18:59:10.855877 21167 net.cpp:100] Creating Layer fc6
I0110 18:59:10.855881 21167 net.cpp:434] fc6 <- pool5
I0110 18:59:10.855893 21167 net.cpp:408] fc6 -> fc6
I0110 18:59:11.342620 21167 net.cpp:150] Setting up fc6
I0110 18:59:11.342670 21167 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:59:11.342674 21167 net.cpp:165] Memory required for data: 85408864
I0110 18:59:11.342685 21167 layer_factory.hpp:77] Creating layer relu6
I0110 18:59:11.342699 21167 net.cpp:100] Creating Layer relu6
I0110 18:59:11.342703 21167 net.cpp:434] relu6 <- fc6
I0110 18:59:11.342710 21167 net.cpp:395] relu6 -> fc6 (in-place)
I0110 18:59:11.342922 21167 net.cpp:150] Setting up relu6
I0110 18:59:11.342931 21167 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:59:11.342934 21167 net.cpp:165] Memory required for data: 85539936
I0110 18:59:11.342937 21167 layer_factory.hpp:77] Creating layer drop6
I0110 18:59:11.342945 21167 net.cpp:100] Creating Layer drop6
I0110 18:59:11.342949 21167 net.cpp:434] drop6 <- fc6
I0110 18:59:11.342954 21167 net.cpp:395] drop6 -> fc6 (in-place)
I0110 18:59:11.342980 21167 net.cpp:150] Setting up drop6
I0110 18:59:11.342986 21167 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:59:11.342989 21167 net.cpp:165] Memory required for data: 85671008
I0110 18:59:11.342993 21167 layer_factory.hpp:77] Creating layer fc7
I0110 18:59:11.343000 21167 net.cpp:100] Creating Layer fc7
I0110 18:59:11.343004 21167 net.cpp:434] fc7 <- fc6
I0110 18:59:11.343009 21167 net.cpp:408] fc7 -> fc7
I0110 18:59:11.502375 21167 net.cpp:150] Setting up fc7
I0110 18:59:11.502425 21167 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:59:11.502430 21167 net.cpp:165] Memory required for data: 85802080
I0110 18:59:11.502440 21167 layer_factory.hpp:77] Creating layer relu7
I0110 18:59:11.502459 21167 net.cpp:100] Creating Layer relu7
I0110 18:59:11.502463 21167 net.cpp:434] relu7 <- fc7
I0110 18:59:11.502470 21167 net.cpp:395] relu7 -> fc7 (in-place)
I0110 18:59:11.502928 21167 net.cpp:150] Setting up relu7
I0110 18:59:11.502939 21167 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:59:11.502943 21167 net.cpp:165] Memory required for data: 85933152
I0110 18:59:11.502946 21167 layer_factory.hpp:77] Creating layer drop7
I0110 18:59:11.502955 21167 net.cpp:100] Creating Layer drop7
I0110 18:59:11.502960 21167 net.cpp:434] drop7 <- fc7
I0110 18:59:11.502965 21167 net.cpp:395] drop7 -> fc7 (in-place)
I0110 18:59:11.502995 21167 net.cpp:150] Setting up drop7
I0110 18:59:11.503001 21167 net.cpp:157] Top shape: 8 4096 (32768)
I0110 18:59:11.503005 21167 net.cpp:165] Memory required for data: 86064224
I0110 18:59:11.503007 21167 layer_factory.hpp:77] Creating layer fc8
I0110 18:59:11.503015 21167 net.cpp:100] Creating Layer fc8
I0110 18:59:11.503017 21167 net.cpp:434] fc8 <- fc7
I0110 18:59:11.503036 21167 net.cpp:408] fc8 -> fc8
I0110 18:59:11.503170 21167 net.cpp:150] Setting up fc8
I0110 18:59:11.503176 21167 net.cpp:157] Top shape: 8 1 (8)
I0110 18:59:11.503180 21167 net.cpp:165] Memory required for data: 86064256
I0110 18:59:11.503185 21167 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0110 18:59:11.503192 21167 net.cpp:100] Creating Layer fc8_fc8_0_split
I0110 18:59:11.503196 21167 net.cpp:434] fc8_fc8_0_split <- fc8
I0110 18:59:11.503201 21167 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0110 18:59:11.503207 21167 net.cpp:408] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0110 18:59:11.503242 21167 net.cpp:150] Setting up fc8_fc8_0_split
I0110 18:59:11.503248 21167 net.cpp:157] Top shape: 8 1 (8)
I0110 18:59:11.503252 21167 net.cpp:157] Top shape: 8 1 (8)
I0110 18:59:11.503254 21167 net.cpp:165] Memory required for data: 86064320
I0110 18:59:11.503257 21167 layer_factory.hpp:77] Creating layer accuracy
I0110 18:59:11.503264 21167 net.cpp:100] Creating Layer accuracy
I0110 18:59:11.503268 21167 net.cpp:434] accuracy <- fc8_fc8_0_split_0
I0110 18:59:11.503273 21167 net.cpp:434] accuracy <- label_data_0_split_0
I0110 18:59:11.503278 21167 net.cpp:408] accuracy -> accuracy
I0110 18:59:11.503285 21167 net.cpp:150] Setting up accuracy
I0110 18:59:11.503290 21167 net.cpp:157] Top shape: (1)
I0110 18:59:11.503293 21167 net.cpp:165] Memory required for data: 86064324
I0110 18:59:11.503299 21167 layer_factory.hpp:77] Creating layer loss
I0110 18:59:11.503305 21167 net.cpp:100] Creating Layer loss
I0110 18:59:11.503309 21167 net.cpp:434] loss <- fc8_fc8_0_split_1
I0110 18:59:11.503314 21167 net.cpp:434] loss <- label_data_0_split_1
I0110 18:59:11.503317 21167 net.cpp:408] loss -> loss
I0110 18:59:11.503325 21167 layer_factory.hpp:77] Creating layer loss
I0110 18:59:11.503548 21167 net.cpp:150] Setting up loss
I0110 18:59:11.503557 21167 net.cpp:157] Top shape: (1)
I0110 18:59:11.503561 21167 net.cpp:160]     with loss weight 1
I0110 18:59:11.503569 21167 net.cpp:165] Memory required for data: 86064328
I0110 18:59:11.503573 21167 net.cpp:226] loss needs backward computation.
I0110 18:59:11.503577 21167 net.cpp:228] accuracy does not need backward computation.
I0110 18:59:11.503582 21167 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0110 18:59:11.503584 21167 net.cpp:226] fc8 needs backward computation.
I0110 18:59:11.503588 21167 net.cpp:226] drop7 needs backward computation.
I0110 18:59:11.503592 21167 net.cpp:226] relu7 needs backward computation.
I0110 18:59:11.503593 21167 net.cpp:226] fc7 needs backward computation.
I0110 18:59:11.503597 21167 net.cpp:226] drop6 needs backward computation.
I0110 18:59:11.503600 21167 net.cpp:226] relu6 needs backward computation.
I0110 18:59:11.503603 21167 net.cpp:226] fc6 needs backward computation.
I0110 18:59:11.503607 21167 net.cpp:226] pool5 needs backward computation.
I0110 18:59:11.503612 21167 net.cpp:226] relu5 needs backward computation.
I0110 18:59:11.503614 21167 net.cpp:226] conv5 needs backward computation.
I0110 18:59:11.503618 21167 net.cpp:226] relu4 needs backward computation.
I0110 18:59:11.503621 21167 net.cpp:226] conv4 needs backward computation.
I0110 18:59:11.503624 21167 net.cpp:226] relu3 needs backward computation.
I0110 18:59:11.503628 21167 net.cpp:226] conv3 needs backward computation.
I0110 18:59:11.503631 21167 net.cpp:226] pool2 needs backward computation.
I0110 18:59:11.503635 21167 net.cpp:226] norm2 needs backward computation.
I0110 18:59:11.503638 21167 net.cpp:226] relu2 needs backward computation.
I0110 18:59:11.503641 21167 net.cpp:226] conv2 needs backward computation.
I0110 18:59:11.503645 21167 net.cpp:226] pool1 needs backward computation.
I0110 18:59:11.503648 21167 net.cpp:226] norm1 needs backward computation.
I0110 18:59:11.503653 21167 net.cpp:226] relu1 needs backward computation.
I0110 18:59:11.503655 21167 net.cpp:226] conv1 needs backward computation.
I0110 18:59:11.503659 21167 net.cpp:228] label_data_0_split does not need backward computation.
I0110 18:59:11.503669 21167 net.cpp:228] data does not need backward computation.
I0110 18:59:11.503677 21167 net.cpp:228] data does not need backward computation.
I0110 18:59:11.503680 21167 net.cpp:270] This network produces output accuracy
I0110 18:59:11.503684 21167 net.cpp:270] This network produces output loss
I0110 18:59:11.503700 21167 net.cpp:283] Network initialization done.
I0110 18:59:11.503770 21167 solver.cpp:60] Solver scaffolding done.
I0110 18:59:11.504283 21167 caffe.cpp:251] Starting Optimization
I0110 18:59:11.504289 21167 solver.cpp:279] Solving AlexNet
I0110 18:59:11.504292 21167 solver.cpp:280] Learning Rate Policy: step
I0110 18:59:11.506007 21167 solver.cpp:337] Iteration 0, Testing net (#0)
I0110 19:02:24.097272 21167 solver.cpp:404]     Test net output #0: accuracy = 0.983739
I0110 19:02:24.097364 21167 solver.cpp:404]     Test net output #1: loss = 0.22349 (* 1 = 0.22349 loss)
I0110 19:02:24.259896 21167 solver.cpp:228] Iteration 0, loss = 0
I0110 19:02:24.259928 21167 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0110 19:02:24.259943 21167 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0110 19:04:53.185160 21167 solver.cpp:228] Iteration 200, loss = 87.3365
I0110 19:04:53.185287 21167 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0110 19:04:53.185297 21167 sgd_solver.cpp:106] Iteration 200, lr = 0.01
